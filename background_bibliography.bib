@article{Adams2015,
author = {Adams, Ryan and Gorman, Katherine and Perlich, Claudia},
journal = {Talking Machines Podcasts},
title = {{Working With Data and Machine Learning in Advertising}},
volume = {13},
year = {2015}
}
@article{Alexandre2014,
author = {Alexandre, Dalyac},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Alexandre - 2014 - Classification of Pipe Weld Images with Deep Neural Networks — Final Report —.pdf:pdf},
pages = {1--72},
title = {{Classification of Pipe Weld Images with Deep Neural Networks — Final Report —}},
year = {2014}
}
@article{Altshuler2011,
author = {Altshuler, Yaniv and Pentland, Alex Sandy},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Altshuler, Pentland - 2011 - Information Flow in Networks — Trendsetters , Bellwethers and Shepherd Dogs.pdf:pdf},
journal = {Workshop on Decision Making in Social Networks},
title = {{Information Flow in Networks — Trendsetters , Bellwethers and Shepherd Dogs}},
year = {2011}
}
@article{Ankerst1999,
abstract = {Satisfying the basic requirements of accuracy and understandability of a classifier, decision tree classifiers have become very popular. Instead of constructing the decision tree by a sophisticated algorithm, we introduce a fully interactive method based on a multidimen- sional visualization technique and appropriate interaction capabilities. Thus, domain knowl- edge of an expert can be profitably included in the tree construction phase. Furthermore, after the interactive construction of a decision tree, the user has a much deeper understanding of the data than just knowing the decision tree generated by an arbitrary algorithm. The inter- active approach also overcomes the limitation of most decision trees which are fixed to binary splits for numeric attributes and which do not allow to backtrack in the tree construction phase. Our performance evaluation with sev- eral well-known datasets demonstrates that even users with no a priori knowledge of the data construct a decision tree with an accuracy similar to the tree generated by state of the art algorithms. Additionally, visual interactive classification significantly reduces the tree size and improves the understandibility of the resulting decision tree.},
author = {Ankerst, Mihael and Elsen, Christian and Ester, Martin and Kriegel, Hans-Peter},
doi = {10.1145/312129.312298},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/Visualising Descision Trees.pdf:pdf},
isbn = {1581131437},
issn = {1581131437},
journal = {Training},
pages = {392--396},
title = {{Visual classification: an interactive approach to decision tree construction}},
url = {http://www.dbs.informatik.uni-muenchen.de/Publikationen/Papers/Kdd-99.final.pdf},
volume = {1},
year = {1999}
}
@article{Ba2013,
abstract = {Recently, it was shown that deep neural networks can perform very well if the activities of hidden units are regularized during learning, e.g, by randomly dropping out 50\% of their activities. We describe a method called ‘standout’ in which a binary belief network is overlaid on a neural network and is used to regularize of its hidden units by selectively setting activities to zero. This ‘adaptive dropout network’ can be trained jointly with the neural network by approximately computing local expectations of binary dropout variables, computing derivatives using back-propagation, and using stochastic gradient descent. Interestingly, experiments show that the learnt dropout network parameters recapitulate the neural network parameters, suggesting that a good dropout network regularizes activities according to magnitude. When evaluated on the MNIST and NORB datasets, we found that our method achieves lower classiﬁcation error rates than other feature learning methods, including standard dropout, denoising auto-encoders, and restricted Boltzmann machines. For example, our method achieves 0.80\% and 5.8\% errors on the MNIST and NORB test sets, which is better than state-of-the-art results obtained using feature learning methods, including those that use convolutional architectures.},
author = {Ba, J and Frey, B},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/5032-adaptive-dropout-for-training-deep-neural-networks.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {1--9},
title = {{Adaptive dropout for training deep neural networks}},
url = {http://papers.nips.cc/paper/5032-adaptive-dropout-for-training-deep-neural-networks},
year = {2013}
}
@article{Ba2015,
abstract = {A model that uses a convolution between an identitiy network and a spatial attention network to determine a sequency of digits from photographs of house numbers. There also is a LSTM network to integrate the input from the successive glimpses that also determines the next glimpse.},
archivePrefix = {arXiv},
arxivId = {arXiv:1412.7755v2},
author = {Ba, Jimmy Lei and Mnih, V. and Kavukcuoglu, Koray},
eprint = {arXiv:1412.7755v2},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/1412.7755v2.pdf:pdf},
journal = {Iclr},
keywords = {deep learning,digit recognition,neural network},
pages = {arXiv:1412.7755v2},
title = {{Multiple object recognition with visual attention}},
year = {2015}
}
@article{Bardenet2013,
abstract = {Hyperparameter learning has traditionally been a manual task because of the limited number of trials. Today's computing infrastructures allow bigger evaluation budgets, thus opening the way for algorithmic approaches. Recently, surrogate-based optimization was successfully applied to hyperparameter learning for deep belief networks and to WEKA classifiers. The methods combined brute force computational power with model building about the behavior of the error function in the hyperparameter space, and they could significantly improve on manual hyperparameter tuning. What may make experienced practitioners even better at hyperparameter optimization is their ability to generalize across similar learning problems. In this paper, we propose a generic method to incorporate knowledge from previous experiments when simultaneously tuning a learning algorithm on new problems at hand. To this end, we combine surrogate-based ranking and optimization techniques for surrogate-based collaborative tuning (SCoT). We demonstrate SCoT in two experiments where it outperforms standard tuning techniques and single-problem surrogate-based optimization.},
author = {Bardenet, R\'{e}mi and Brendel, M\'{a}ty\'{a}s and K\'{e}gl, Bal\'{a}zs and Sebag, Mich\`{e}le},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/bardenet13.pdf:pdf},
journal = {Proceedings of the 30th International Conference on Machine Learning (ICML-13)},
number = {2},
pages = {199--207},
title = {{Collaborative hyperparameter tuning}},
url = {http://hal.archives-ouvertes.fr/in2p3-00907381/$\backslash$nhttp://jmlr.csail.mit.edu/proceedings/papers/v28/bardenet13.pdf},
volume = {28},
year = {2013}
}
@article{Battista1994,
abstract = {Several data presentation problems involve drawing graphs so that they are easy to read and understand. Examples include circuit schematics and software engineering diagrams. In this paper we present a bibliographic survey on algorithms whose goal is to produce aesthetically pleasing drawings of graphs. Research on this topic is spread over the broad spectrum of Computer Science. This bibliography constitutes an attempt to encompass both theoretical and application oriented papers from disparate areas.},
author = {Battista, Giuseppe Di and Eades, Peter and Tamassia, Roberto and Tollis, Ioannis G},
doi = {10.1016/0925-7721(94)00014-X},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/1-s2.0-092577219400014X-main.pdf:pdf},
isbn = {0925-7721},
issn = {09257721},
journal = {Computational Geometry},
number = {5},
pages = {235--282},
title = {{Algorithms for drawing graphs: an annotated bibliography}},
volume = {4},
year = {1994}
}
@article{Becker2001,
abstract = {The simple Bayesian classifier (SBC) sometimes called Naive-Bayes, is built based on a conditional independence model of each attribute given the class. The model was previously shown to be surprisingly robust to obvious violations of this independence assumption, yielding accurate classification models even when there are clear conditional dependencies. The SBC can serve as an excellent tool for initial exploratory data analysis when coupled with a visualizer that makes its structure comprehensible. We describe such a visual representation of the SBC model that has been successfully implemented. We describe the requirements we had for such visualization and the design decisions we made to satisfy them.},
author = {Becker, Barry and Kohavi, Ron and Sommerfield, D.},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/Visualising the Naieve Bayesian Network.pdf:pdf},
journal = {Information visualization in data mining and knowledge discovery},
keywords = {1 introduction to the,a labeled training set,a model that maps,classi cation,gorithm,in supervised classi cation,is presented to the,learning,learning al-,naive-bayes,simple,simple-bayesian classi er,the learner uses the,training set to build,unlabeled instances,visualization},
pages = {237--249},
title = {{Visualizing the simple Bayesian classifier}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=2gSZv1fikJoC\&amp;oi=fnd\&amp;pg=PA237\&amp;dq=Visualizing+the+Simple+Bayesian+Classifier\&amp;ots=THFPUgGO1-\&amp;sig=j1S-ESo9o\_vC00W-4gV-Acay6Go},
volume = {18},
year = {2001}
}
@article{Belkin2002,
author = {Belkin, M and Niyogi, P},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/LEM\_NIPS\_01.pdf:pdf},
title = {{Laplacian Eigenmaps and spectral techniques for embedding and clustering}},
year = {2002}
}
@article{Bengio2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1206.5533v2},
author = {Bengio, Yoshua},
eprint = {arXiv:1206.5533v2},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/1206.5533v2.pdf:pdf},
journal = {arXiv},
title = {{Practical Recommendations for Gradient-Based Training of Deep Architectures}},
year = {2012}
}
@article{Bengio2003,
abstract = {A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difficult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a significant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach significantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts.},
author = {Bengio, Yoshua and Ducharme, R\'{e}jean and Vincent, Pascal and Janvin, Christian},
doi = {10.1162/153244303322533223},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/BengioDVJ03.pdf:pdf},
isbn = {1532-4435},
issn = {15324435},
journal = {The Journal of Machine Learning Research},
keywords = {artificial neural networks,curse of dimensionality,distributed representation,statistical language modeling},
pages = {1137--1155},
title = {{A Neural Probabilistic Language Model}},
volume = {3},
year = {2003}
}
@unpublished{Bengio-et-al-2015-Book,
annote = {Book in preparation for MIT Press},
author = {Bengio, Yoshua and Goodfellow, Ian J and Courville, Aaron},
title = {{Deep Learning}},
url = {http://www.iro.umontreal.ca/~bengioy/dlbook},
year = {2015}
}
@article{Bergstra,
author = {Bergstra, James and Bardenet, Remi and Bengio, Yoshua and Kegl, Balazs},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/4443-algorithms-for-hyper-parameter-optimization.pdf:pdf},
pages = {1--9},
title = {{Algorithms for Hyper-Parameter Optimization}}
}
@article{Bergstra2012,
abstract = {Grid search and manual search are the most widely used strategies for hyper-parameter optimiza- tion. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a compar- ison with a large previous study that used grid search and manual search to configure neural net- works and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising con- figuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent “High Throughput”methods achieve surprising success—they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that randomsearch is a natural base- line against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.},
author = {Bergstra, James and Bengio, Yoshua},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/bergstra12a.pdf:pdf},
isbn = {1532-4435},
issn = {1532-4435},
journal = {Journal ofMachine Learning Research},
keywords = {deep learning,global optimization,model selection,neural networks,response surface},
pages = {281--305},
title = {{Random Search for Hyper-Parameter Optimization}},
volume = {13},
year = {2012}
}
@article{Bergstra2013,
abstract = {超パラメータのベイズ最適化},
author = {Bergstra, James and Yamins, D and Cox, D},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/bergstra13.pdf:pdf},
journal = {Proceedings of the 30th International Conference on Machine Learning},
pages = {115--123},
title = {{Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures}},
url = {http://jmlr.org/proceedings/papers/v28/bergstra13.html},
year = {2013}
}
@article{Borji2014,
author = {Borji, Ali and Itti, Laurent},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/Paper 9.pdf:pdf},
journal = {Computer Vision and Pattern Recognition},
pages = {1},
title = {{Compuer vision vs. human vision: What can be learned?}},
year = {2014}
}
@misc{Bostock2011a,
author = {Bostock, Michael and Heer, Jeffrey and Ogievetsky, Vadim},
keywords = {d3,d3.js,dom,javascript,visualization},
title = {{D3.js - Data-Driven Documents}},
url = {http://d3js.org/},
urldate = {2015-06-12},
year = {2011}
}
@article{Bostock2011,
author = {Bostock, Michael and Ogievetsky, Vadim and Heer, Jeffrey},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/2011-D3-InfoVis.pdf:pdf},
number = {March},
title = {{D 3 : Data-Driven Documents}},
year = {2011}
}
@article{Boyd2000,
author = {Boyd, John P},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/eng403\_chap2\_tuftegospel.pdf:pdf},
journal = {Scientific Visualization and Information Architecture},
number = {2},
pages = {27--92},
title = {{The Gospel According to Tufte BT  - Scientific Visualization and Information Architecture}},
url = {papers2://publication/uuid/CD749B2B-A4DC-4709-BA92-AB86B6D35AF1},
year = {2000}
}
@article{Bruckner2013,
author = {Bruckner, Daniel and Rosen, Joshua and Sparks, Evan R},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/DeepVizPaper.pdf:pdf},
title = {{DeepViz : Visualizing Convolutional Neural Networks for Image Classification}},
year = {2013}
}
@article{Bruna2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1203.1513v2},
author = {Bruna, Joan and Polytechnique, Ecole},
eprint = {arXiv:1203.1513v2},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/1203.1513.pdf:pdf},
pages = {1--15},
title = {{Invariant Scattering Convolution Networks ´}},
year = {2012}
}
@article{Bruna,
archivePrefix = {arXiv},
arxivId = {arXiv:1301.3537v1},
author = {Bruna, Joan and Szlam, Arthur and Lecun, Yann},
eprint = {arXiv:1301.3537v1},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/1506.02753.pdf:pdf},
pages = {1--4},
title = {{with Convolutional Networks}}
}
@article{Burkhard2004,
abstract = { This work focuses on an aspect which has been neglected, but which is decisive: the transfer of knowledge to different stakeholders; especially the transfer of insights derived from information visualization tools. In knowledge management, the transfer of knowledge is a core process, which can be improved by using our innate abilities to process visual representations. The potential of visualizations are manifold. But business managers miss a holistic framework on the use of visualization methods for information exploration and communication tasks. This paper analyzes how architects use visualizations to amplify cognition and to transfer knowledge. It introduces a mediating framework that brings together isolated research directions and defines the new research focus knowledge visualization. Knowledge visualization examines the use of visualizations for the transfer of knowledge between at least two people. We found that the new focus is decisive and has implications for researchers in information visualization and knowledge management.},
author = {Burkhard, R.a.},
doi = {10.1109/IV.2004.1320194},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/01320194.pdf:pdf},
isbn = {0-7695-2177-0},
issn = {1093-9547},
journal = {Proceedings. Eighth International Conference on Information Visualisation, 2004. IV 2004.},
keywords = {information,knowledge visualization},
title = {{Learning from architects: the difference between knowledge visualization and information visualization}},
year = {2004}
}
@article{Butz2009,
author = {Butz, Prof Andreas},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Butz - 2009 - The Problem Classic examples • Enron example.pdf:pdf},
title = {{The Problem Classic examples • Enron example}},
year = {2009}
}
@article{Caragea2001,
abstract = {This paper discusses visual methods that can be used to understand$\backslash$nand interpret the results of classi cation using support vector machines$\backslash$n(SVM) on data with continuous real-valued variables. SVM induction$\backslash$nalgorithms build pattern classi ers by identifying a maximal margin$\backslash$nseparating hyperplane from training examples in high dimensional$\backslash$npattern spaces or spaces induced by suitable nonlinear kernel transformations$\backslash$nover pattern spaces. SVM have been demonstrated to be quite eectiveinanumber$\backslash$nof practical pattern classi cation tasks. Since the separating hyperplane$\backslash$nis de ned in terms of more than two variables it is necessary to$\backslash$nuse visual techniques that can navigate the viewer through high-dimensional$\backslash$nspaces. We demonstrate the use of projection-based tour methods to$\backslash$ngain useful insights into SVM classi ers with linear kernels on 8-dimensional$\backslash$ndata.},
author = {Caragea, Doina and Cook, Dianne and Honavar, Vasant},
doi = {10.1145/502512.502547},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/Visualising SVMs.pdf:pdf},
isbn = {158113391X},
journal = {Proceedings of the KDD Conference},
keywords = {jabref:noKeywordAssigned},
pages = {251--256},
title = {{Gaining Insights into Support Vector Machine Pattern Classifiers Using Projection-Based Tour Methods}},
year = {2001}
}
@article{Card2009,
author = {Card, S. and Mackinlay, J.D and Scheiderman, B},
doi = {10.1002/wics.89},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Card, Mackinlay, Scheiderman - 2009 - Information visualization.pdf:pdf},
isbn = {1558605339},
issn = {19395108},
journal = {Human-Computer Interaction: Design Issues, Solutions, and Applications},
pages = {181},
pmid = {21283854},
title = {{Information visualization}},
year = {2009}
}
@article{Card1999,
author = {Card, Stuart K. and Mackinlay, Jock and Shneiderman, Ben},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Card, Mackinlay, Shneiderman - 1999 - Information Visualization.pdf:pdf},
isbn = {1-55860-533-9},
journal = {Readings in Information Visualization: Using Vision to Think},
pages = {1--34},
title = {{Information Visualization}},
year = {1999}
}
@article{Carlsson2008,
abstract = {In this study we concentrate on qualitative topological analysis of the local behavior of the space of natural images. To this end, we use a space of 3 by 3 high-contrast patches M. We develop a theoretical model for the highdensity 2-dimensional submanifold of M showing that it has the topology of the Klein bottle. Using our topological software package PLEX we experimentally verify our theoretical conclusions. We use polynomial representation to give coordinatization to various subspaces of M. We find the best-fitting embedding of the Klein bottle into the ambient space of M. Our results are currently being used in developing a compression algorithm based on a Klein bottle dictionary.},
author = {Carlsson, Gunnar and Ishkhanov, Tigran and {De Silva}, Vin and Zomorodian, Afra},
doi = {10.1007/s11263-007-0056-x},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/carlsson-ijcv08.pdf:pdf},
isbn = {09205691},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {Filtration,Klein bottle,Manifold,Natural images,Persistent homology,Topology},
number = {1},
pages = {1--12},
title = {{On the local behavior of spaces of natural images}},
volume = {76},
year = {2008}
}
@article{Chau2011,
abstract = {We present APOLO, a system that uses a mixed-initiative approach to help people interactively explore and make sense of large network datasets. It combines visualization, rich user interaction and machine learning to engage the user in bottom-up sensemaking to gradually build up an understanding over time by starting small, rather than starting big and drilling down. APOLO helps users find relevant information by specifying exemplars, and then using a machine learning method called Belief Propagation to infer which other nodes may be of interest. We demonstrate APOLO's usage and benefits using a Google Scholar citation graph, consisting of 83,000 articles (nodes) and 150,000 citations relationships. Copyright 2011 ACM.},
author = {Chau, D H and Kittur, a and Hong, J I and Faloutsos, C},
doi = {10.1145/2020408.2020524},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/apolo\_demo.pdf:pdf},
isbn = {9781450308137},
journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
keywords = {Belief propagation; Citation graphs; Data sets; Go,Data mining; Data visualization; User interfaces;,Learning systems},
pages = {739--742},
title = {{Apolo: Interactive large graph sensemaking by combining machine learning and visualization}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80052690538\&partnerID=40\&md5=1811deef9ebcc10b5325c6c2d633a213},
year = {2011}
}
@article{Chelaru2014,
abstract = {Visualization is an integral aspect of genomics data analysis. Algorithmic-statistical analysis and interactive visualization are most effective when used iteratively. Epiviz (http://epiviz.cbcb.umd.edu/), a web-based genome browser, and the Epivizr Bioconductor package allow interactive, extensible and reproducible visualization within a state-of-the-art data-analysis platform.},
author = {Chelaru, Florin and Smith, Llewellyn and Goldstein, Naomi and Bravo, H\'{e}ctor Corrada},
doi = {10.1038/nmeth.3038},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/nmeth.3038.pdf:pdf},
issn = {1548-7091},
journal = {Nature Methods},
number = {August},
pages = {12--15},
title = {{Epiviz: interactive visual analytics for functional genomics data}},
url = {http://www.nature.com/doifinder/10.1038/nmeth.3038},
volume = {11},
year = {2014}
}
@article{Chernoff1973,
abstract = {A novel method of representing multivariate data is presented. Each point in k-dimensional space, k<18, is represented by a cartoon of a face whose features, such as length of nose and curvature of mouth, correspond to componetns of the point. Thus every multivariate observation is visualized as a computer-drawn face. This presentation makes it easy for the human mind to grasp many of the essential regularities and irregularities present in the data. Other graphical representations are described briefly.},
author = {Chernoff, Herman},
doi = {10.1080/01621459.1973.10482434},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/chernoff (1973) the use of faces to represent points in k-dimensional space graphically.pdf:pdf},
isbn = {01621459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
number = {342},
pages = {361--368},
title = {{The use of faces to represent points in k-dimensional space graphically.}},
volume = {68},
year = {1973}
}
@article{Childs2013,
author = {Childs, H and Geveci, Berk and Schroeder, Will},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/ceriv-lbnl-report.pdf:pdf},
journal = {Computer},
number = {May},
title = {{Research challenges for visualization software}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6515547},
year = {2013}
}
@article{Cho2014,
abstract = {In this paper, we propose a novel neural network model called RNN Encoder--Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder--Decoder as an additional feature in the existing linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.},
archivePrefix = {arXiv},
arxivId = {1406.1078},
author = {Cho, Kyunghyun and van Merrienboer, Bart and Gulcehre, Caglar and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
eprint = {1406.1078},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/1406.1078v1.pdf:pdf},
journal = {arXiv},
keywords = {decoder,for statistical machine translation,rning phrase representations using,rnn encoder},
title = {{Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation}},
url = {http://arxiv.org/abs/1406.1078},
year = {2014}
}
@article{Choi2005,
abstract = { In this paper, a new learning law for one-dimensional topology preserving neural networks is presented in which the output weights of the neural network converge to a set that produces a predefined winning neuron coordinate probability distribution, when the probability density function of the input signal is unknown and not necessarily uniform. The learning algorithm also produces an orientation preserving homeomorphic function from the known neural coordinate domain to the unknown input signal space, which maps a predefined neural coordinate probability density function into the unknown probability density function of the input signal. The convergence properties of the proposed learning algorithm are analyzed using the ODE approach and verified by a simulation study.},
author = {Choi, Jongeun Choi Jongeun and Horowitz, R.},
doi = {10.1109/ACC.2005.1470151},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/145c\_choi\_ACC05\_neural\_net.pdf:pdf},
isbn = {0-7803-9098-9},
issn = {0743-1619},
journal = {Proceedings of the 2005, American Control Conference, 2005.},
keywords = {Adaptive systems,Neural networks,Statistical learning},
pages = {1343--1350},
title = {{Topology preserving neural networks that achieve a prescribed feature map probability density distribution}},
year = {2005}
}
@article{Cleveland1984,
abstract = {The subject of graphical methods for data analysis and for data presentation needs a scientific foundation. In this article we take a few steps in the direction of establishing such a foundation. Our approach is based on graphical perception-the visual decoding of information encoded on graphs-and it includes both theory and experimentation to test the theory. The theory deals with a small but important piece of the whole process of graphical perception. The first part is an identification of a set of elementary perceptual tasks that are carried out when people extract quantitative information from graphs. The second part is an ordering of the tasks on the basis of how accurately people perform them. Elements of the theory are tested by experimentation in which subjects record their judgments of the quantitative information on graphs. The experiments validate these elements but also suggest that the set of elementary tasks should be expanded. The theory provides a guideline for graph construction: Graphs should employ elementary tasks as high in the ordering as possible. This principle is applied to a variety of graphs, including bar charts, divided bar charts, pie charts, and statistical maps with shading. The conclusion is that radical surgery on these popular graphs is needed, and as replacements we offer alternative graphical forms-dot charts, dot charts with grouping, and framed-rectangle charts.},
author = {Cleveland, William S and McGill, Robert},
doi = {10.2307/2288400},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/01621459\%2E1984\%2E10478080.pdf:pdf},
isbn = {0162-1459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
number = {387},
pages = {531--554},
pmid = {17777913},
title = {{Graphical Perception: Theory, Experimentation, and Application to the Development of Graphical Methods}},
volume = {79},
year = {1984}
}
@article{Cleveland1986,
abstract = {Graphical perception is the visual decoding of categorical and quantitative information from a graph. Increasing our basic understanding of graphical perception will allow us to make graphs that convey quantitative information to viewers with more accuracy and efficiency. This paper describes an experiment that was conducted to investigate the accuracy of six basic judgments of graphical perception. Two types of position judgments were found to be the most accurate, length judgments were second, angle and slope judgments were third, and area judgments were last. Distance between judged objects was found to be a factor in the accuracy of the basic judgments.},
author = {Cleveland, William S. and McGill, Robert},
doi = {10.1016/S0020-7373(86)80019-0},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/science.pdf:pdf},
isbn = {0020-7373},
issn = {00207373},
journal = {International Journal of Man-Machine Studies},
number = {5},
pages = {491--500},
title = {{An experiment in graphical perception}},
volume = {25},
year = {1986}
}
@article{Club,
author = {Club, Statistics Journal},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/deep.pdf:pdf},
pages = {1--22},
title = {{Summary and discussion of : “ Why Does Unsupervised Pre-training Help Deep Learning ?”}}
}
@article{Crapo2000,
abstract = {Note: OCR errors may be found in this Reference List extracted from the full text article. ACM has opted to expose the complete List rather than only correct and linked references.},
author = {Crapo, Andrew W. and Waisel, Laurie B. and Wallace, William a. and Willemain, Thomas R.},
doi = {10.1145/347090.347129},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/p218-crapo.pdf:pdf},
isbn = {1581132336},
journal = {ACM Press},
pages = {218--226},
title = {{Visualization and The Process of Modeling: A Cognitive-theoretic View}},
year = {2000}
}
@article{Craven1992,
author = {Craven, Mark W. and Shavlik, Jude W.},
doi = {10.1142/S0218213092000260},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/10.1.1.50.8157.pdf:pdf},
issn = {0218-2130},
journal = {International Journal on Artificial Intelligence Tools},
keywords = {knowledge-based neural networks,neural networks,scienti c visualization},
number = {03},
pages = {399--425},
title = {{Visualizing Learning and Computation in Artificial Neural Networks}},
volume = {01},
year = {1992}
}
@article{Cristina2003,
author = {Cristina, Maria and Oliveira, Ferreira De and Levkowitz, Haim},
doi = {10.1109/TVCG.2003.1207445},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/dimension\_reduction.pdf:pdf},
issn = {1077-2626},
number = {3},
pages = {378--394},
title = {{From Visual Data Exploration to Visual Data Mining : A Survey}},
volume = {9},
year = {2003}
}
@article{Crnovrsanin2014,
abstract = {The growing popularity and diversity of social network applications present new opportunities as well as new challenges. The resulting social networks have high value to business intelligence, sociological studies, organizational studies, epidemical studies, etc. The ability to explore and extract information of interest from the networks is thus crucial. However, these networks are often large and composed of multi-categorical nodes and edges, making it difficult to visualize and reason with conventional methods. In this paper, we show how to combine statistical methods with visualization to address these challenges, and how to arrange layouts differently to better bring out different aspects of the networks. We applied our methods to several social networks to demonstrate their effectiveness in characterizing the networks and clarifying the structures of interest, leading to new findings. © 2013.},
author = {Crnovrsanin, Tarik and Muelder, Chris W. and Faris, Robert and Felmlee, Diane and Ma, Kwan Liu},
doi = {10.1016/j.socnet.2013.12.002},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/1-s2.0-S0378873313001044-main.pdf:pdf},
isbn = {0378-8733, 0378-8733},
issn = {03788733},
journal = {Social Networks},
keywords = {Graph layouts,Information visualization,Network analytics,Social networks},
number = {1},
pages = {56--64},
publisher = {Elsevier B.V.},
title = {{Visualization techniques for categorical analysis of social networks with multiple edge sets}},
url = {http://dx.doi.org/10.1016/j.socnet.2013.12.002},
volume = {37},
year = {2014}
}
@article{Dahl2012,
abstract = {We propose a novel context-dependent (CD) model for large-vocabulary speech recognition (LVSR) that leverages recent advances in using deep belief networks for phone recognition.We describe a pre-trained deep neural network hidden Markov model (DNN-HMM) hybrid architecture that trains the DNN to produce a distribution over senones (tied triphone states) as its output. The deep belief network pre-training algorithm is a robust and often helpful way to initialize deep neural networks generatively that can aid in optimization and reduce generalization error. We il- lustrate the key components of our model, describe the procedure for applying CD-DNN-HMMs to LVSR, and analyze the effects of various modeling choices on performance. Experiments on a chal- lenging business search dataset demonstrate thatCD-DNN-HMMs can significantly outperform the conventional context-dependent Gaussian mixture model (GMM)-HMMs, with an absolute sen- tence accuracy improvement of 5.8\% and 9.2\% (or relative error reduction of 16.0\% and 23.2\%) over theCD-GMM-HMMstrained using the minimum phone error rate (MPE) and maximum-likeli- hood (ML) criteria, respectively.},
author = {Dahl, George E. and Yu, Dong and Deng, Li and Acero, Alex},
doi = {10.1109/TASL.2011.2134090},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/dbn4lvcsr-transaslp.pdf:pdf},
isbn = {1558-7916},
issn = {15587916},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
keywords = {Artificial neural network-hidden Markov model (ANN,context-dependent phone,deep belief network,deep neural network hidden Markov model (DNN-HMM),large-vocabulary speech recognition (LVSR),speech recognition},
number = {1},
pages = {30--42},
title = {{Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition}},
volume = {20},
year = {2012}
}
@misc{Dahl2009,
author = {Dahl, Ryan},
title = {{Node.js}},
url = {https://nodejs.org/},
urldate = {2015-06-12},
year = {2009}
}
@article{Dai2014,
author = {Dai, Andrew M and Olah, Christopher and Le, Quoc V and Corrado, Greg S},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/68.pdf:pdf},
pages = {1--9},
title = {{Document Embedding with Paragraph Vectors}},
year = {2014}
}
@article{Dai2008,
abstract = {BACKGROUND: Profile Hidden Markov Model (HMM) is a powerful statistical model to represent a family of DNA, RNA, and protein sequences. Profile HMM has been widely used in bioinformatics research such as sequence alignment, gene structure prediction, motif identification, protein structure prediction, and biological database search. However, few comprehensive, visual editing tools for profile HMM are publicly available. RESULTS: We develop a visual editor for profile Hidden Markov Models (HMMEditor). HMMEditor can visualize the profile HMM architecture, transition probabilities, and emission probabilities. Moreover, it provides functions to edit and save HMM and parameters. Furthermore, HMMEditor allows users to align a sequence against the profile HMM and to visualize the corresponding Viterbi path. CONCLUSION: HMMEditor provides a set of unique functions to visualize and edit a profile HMM. It is a useful tool for biological sequence analysis and modeling. Both HMMEditor software and web service are freely available.},
author = {Dai, Jianyong and Cheng, Jianlin},
doi = {10.1186/1471-2164-9-S1-S8},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/VIsualising Hidden Markov Models.pdf:pdf},
isbn = {1471-2164 (Electronic)$\backslash$r1471-2164 (Linking)},
issn = {1471-2164},
journal = {BMC genomics},
pages = {S8},
pmid = {18366621},
title = {{HMMEditor: a visual editing tool for profile hidden Markov model.}},
volume = {9 Suppl 1},
year = {2008}
}
@article{Dauphin2014,
abstract = {A central challenge to many fields of science and engineering involves minimizing non-convex error functions over continuous, high dimensional spaces. Gradient descent or quasi-Newton methods are almost ubiquitously used to perform such minimizations, and it is often thought that a main source of difficulty for these local methods to find the global minimum is the proliferation of local minima with much higher error than the global minimum. Here we argue, based on results from statistical physics, random matrix theory, neural network theory, and empirical evidence, that a deeper and more profound difficulty originates from the proliferation of saddle points, not local minima, especially in high dimensional problems of practical interest. Such saddle points are surrounded by high error plateaus that can dramatically slow down learning, and give the illusory impression of the existence of a local minimum. Motivated by these arguments, we propose a new approach to second-order optimization, the saddle-free Newton method, that can rapidly escape high dimensional saddle points, unlike gradient descent and quasi-Newton methods. We apply this algorithm to deep or recurrent neural network training, and provide numerical evidence for its superior optimization performance.},
archivePrefix = {arXiv},
arxivId = {1406.2572},
author = {Dauphin, Yann and Pascanu, Razvan and Gulcehre, Caglar and Cho, Kyunghyun and Ganguli, Surya and Bengio, Yoshua},
eprint = {1406.2572},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/1406.2572.pdf:pdf},
pages = {1--14},
title = {{Identifying and attacking the saddle point problem in high-dimensional non-convex optimization}},
url = {http://arxiv.org/abs/1406.2572},
year = {2014}
}
@article{Dean,
archivePrefix = {arXiv},
arxivId = {arXiv:1503.02531v1},
author = {Dean, Jeff},
eprint = {arXiv:1503.02531v1},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/1503.02531v1.pdf:pdf},
pages = {1--9},
title = {{Distilling the Knowledge in a Neural Network}}
}
@article{DeCamp2012,
abstract = {Thesis (Ph. D.)--Massachusetts Institute of Technology, School of Architecture and Planning, Program in Media Arts and Sciences, February 2013.},
author = {DeCamp, Philip (Philip James)},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/decamp\_phd\_thesis.pdf:pdf},
keywords = {Architecture. Program in Media Arts and Sciences.},
title = {{Data visualization in the first person}},
url = {http://dspace.mit.edu/handle/1721.1/79301},
year = {2012}
}
@article{DeFanti1989,
author = {DeFanti, T a and Brown, M D and McCormick, B H},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/Visualization.pdf:pdf},
journal = {Computer Graphics and Applications, IEEE},
number = {8},
pages = {12--16},
title = {{Visualization: expanding scientific and engineering research opportunities}},
volume = {22},
year = {1989}
}
@article{Demartines1995,
author = {Demartines, Pierre and Herault, Jeanny},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/10.1.1.27.7925.pdf:pdf},
journal = {Kybernetik},
pages = {1--4},
title = {{CCA : Curvilinear Component Analysis " 1 Introduction 2 Algorithm}},
year = {1995}
}
@article{Demiralp2014,
author = {Demiralp, \c{C}ağatay and Bernstein, Michael S. and Heer, Jeffrey},
doi = {10.1109/TVCG.2014.2346978},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/2014-PerceptualKernels-InfoVis.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization \& Computer Graphics (Proc. InfoVis)},
number = {August},
title = {{Learning Perceptual Kernels for Visualization Design}},
url = {http://hci.stanford.edu/~cagatay/projects/pk/perceptual-kernels.pdf},
year = {2014}
}
@article{Deng2014,
author = {Deng, Li},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/keynote-deeplearning-interspeech2014-sept18-removebackups.pdf:pdf},
title = {{Achievements \& Challenges of Deep Learning Main message of this talk Deep Learning}},
year = {2014}
}
@article{Deng2013,
abstract = {This book is aimed to provide an overview of general deep learning methodology and its applications to a variety of signal and information processing tasks. The application areas are chosen with the following three criteria: 1) expertise or knowledge of the authors; 2) the application areas that have already been transformed by the successful use of deep learning technology, such as speech recognition and computer vision; and 3) the application areas that have the potential to be impacted significantly by deep learning and that have gained concentrated research efforts, including natural language and text processing, information retrieval, and multimodal information processing empowered by multi-task deep learning. In Chapter 1, we provide the background of deep learning, as intrinsically connected to the use of multiple layers of nonlinear transformations to derive features from the sensory signals such as speech and visual images. In the most recent literature, deep learning is embodied also as representation learning, which involves a hierarchy of features or concepts where higher-level representations of them are defined from lower-level ones and where the same lower-level representations help to define higher-level ones. In Chapter 2, a brief historical account of deep learning is presented. In particular, selected chronological development of speech recognition is used to illustrate the recent impact of deep learning that has become a dominant technology in speech recognition industry within only a few years since the start of a collaboration between academic and industrial researchers in applying deep learning to speech recognition. In Chapter 3, a three-way classification scheme for a large body of work in deep learning is developed. We classify a growing number of deep learning techniques into unsupervised, supervised, and hybrid categories, and present qualitative descriptions and a literature survey for each category. From Chapter 4 to Chapter 6, we discuss in detail three popular deep networks and related learning methods, one in each category. Chapter 4 is devoted to deep autoencoders as a prominent example of the unsupervised deep learning techniques. Chapter 5 gives a major example in the hybrid deep network category, which is the discriminative feed-forward neural network for supervised learning with many layers initialized using layer-by-layer generative, unsupervised pre-training. In Chapter 6, deep stacking networks and several of the variants are discussed in detail, which exemplify the discriminative or supervised deep learning techniques in the three-way categorization scheme. In Chapters 7-11, we select a set of typical and successful applications of deep learning in diverse areas of signal and information processing and of applied artificial intelligence. In Chapter 7, we review the applications of deep learning to speech and audio processing, with emphasis on speech recognition organized according to several prominent themes. In Chapters 8, we present recent results of applying deep learning to language modeling and natural language processing. Chapter 9 is devoted to selected applications of deep learning to information retrieval including Web search. In Chapter 10, we cover selected applications of deep learning to image object recognition in computer vision. Selected applications of deep learning to multi-modal processing and multi-task learning are reviewed in Chapter 11. Finally, an epilogue is given in Chapter 12 to summarize what we presented in earlier chapters and to discuss future challenges and directions.},
author = {Deng, Li and Yu, Dong},
doi = {10.1136/bmj.319.7209.0a},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Deng, Yu - 2013 - Deep Learning Methods and Aopplications.pdf:pdf},
isbn = {9781405161251},
issn = {09598138},
journal = {Foundations and Trends in Signal Processing},
number = {3-4},
pages = {197----387},
pmid = {10463930},
title = {{Deep Learning: Methods and Aopplications}},
volume = {7},
year = {2013}
}
@article{Dholakiya2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1505.06605v1},
author = {Dholakiya, Jaley H and Kiran, Ravi},
eprint = {arXiv:1505.06605v1},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/1505.06605.pdf:pdf},
keywords = {all or part of,computation,computer vision,graphical user interface,neural networks,open source,or hard copies of,parallel,permission to make digital,this work for},
title = {{Expresso : A user-friendly GUI for designing , training and using Convolutional Neural Networks}},
year = {2015}
}
@article{Dimopoulos1999,
abstract = {The aim of the present work is to propose a model for the estimation of lead concentration in grasses using urban descriptors easily accessible and to study the specific effect of each descriptor on lead concentration, six descriptors were considered: the density of vegetation, the vegetation height, wind velocity, height of building, distance of adjacent street, traffic volume. Lead concentrations were determined in one grass species, Cynodon dactylon (L.) Pers, (Bermuda grass), collected from 30 different locations in Athens city. The proposed model is a multilayer perception (MLP) trained by backpropagation. The predictive quality of the model was judged by two cross-validation methods. The generalization ability of the model is confirmed by a determination coefficient higher than 0.91. The study of the first partial derivatives of the output of the MLP with respect to each input is used to identify of the factors influencing the lead concentration and the mode of action of each factor. Results allow to classify the environmental descriptors by their decreasing influence on lead concentration: distance of adjacent street, traffic volume density of vegetation, wind velocity, height of building and vegetation height.},
author = {Dimopoulos, Ioannis and Chronopoulos, J. and Chronopoulou-Sereli, a. and Lek, Sovan},
doi = {10.1016/S0304-3800(99)00099-X},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/10.1.1.129.8537.pdf:pdf},
issn = {03043800},
journal = {Ecological Modelling},
keywords = {Backpropagation,Heavy metal,Modelling,Multiple regression,Sensitivity analysis,Urban pollution},
number = {2-3},
pages = {157--165},
title = {{Neural network models to study relationships between lead concentration in grasses and permanent urban descriptors in Athens city (Greece)}},
volume = {120},
year = {1999}
}
@article{Dix2002,
abstract = {The use of random algorithms in many areas of computer science has enabled the solution of otherwise intractable problems. In this paper we propose that random sampling can make the visualisation of large datasets both more computationally efficient and more perceptually effective. We review the explicit uses of randomness and the related deterministic techniques in the visualisation literature. We then discuss how sampling can augment existing systems. Furthermore, we demonstrate a novel 2D zooming interface the Astral Telescope Visualiser, a visualisation suggested and enabled by sampling. We conclude by considering some general usability and technical issues raised by sampling-based visualisation.},
author = {Dix, a. and Ellis, G.},
doi = {10.1145/1556262.1556289},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Dix, Ellis - 2002 - By Chance - Enhancing Interaction with Large Data Sets Through Statistical Sampling.pdf:pdf},
isbn = {1-58113-537-8},
keywords = {QA75 Electronic computers. Computer science},
title = {{By Chance - Enhancing Interaction with Large Data Sets Through Statistical Sampling}},
url = {http://eprints.lancs.ac.uk/12143/},
year = {2002}
}
@article{Domhan2014,
author = {Domhan, Tobias},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/14-AUTOML-ExtrapolatingLearningCurves4.pdf:pdf},
title = {{Extrapolating Learning Curves of Deep Neural Networks}},
year = {2014}
}
@misc{Domingos2012,
abstract = {MACHINE LEARNING SYSTEMS automatically learn programs from data. This is often a very attractive alternative to manually constructing them, and in the last decade the use of machine learning has spread rapidly throughout computer science and beyond. Machine learning is used in Web search, spam filters, recommender systems, ad placement, credit scoring, fraud detection, stock trading, drug design, and many other applications. A recent report from the McKinsey Global Institute asserts that machine learning (a.k.a. data mining or predictive analytics) will be the driver of the next big wave of innovation. Several fine textbooks are available to interested practitioners and researchers (for example, Mitchell and Witten et al.). However, much of the “folk knowledge” that is needed to successfully develop machine learning applications is not readily available in them. As a result, many machine learning projects take much longer than necessary or wind up producing less-than-ideal results. Yet much of this folk knowledge is fairly easy to communicate. This is the purpose of this article.},
author = {Domingos, Pedro},
booktitle = {Communications of the ACM},
doi = {10.1145/2347736.2347755},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Domingos - 2012 - A few useful things to know about machine learning.pdf:pdf},
isbn = {0001-0782},
issn = {00010782},
title = {{A few useful things to know about machine learning}},
year = {2012}
}
@article{Donahue2013,
abstract = {We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be re-purposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms.},
archivePrefix = {arXiv},
arxivId = {1310.1531},
author = {Donahue, Jeff and Jia, Yangqing and Vinyals, Oriol and Hoffman, Judy and Zhang, Ning and Tzeng, Eric and Darrell, Trevor},
eprint = {1310.1531},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/1310.1531v1.pdf:pdf},
isbn = {9781634393973},
journal = {International Conference on Machine Learning},
pages = {647--655},
title = {{DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition}},
url = {http://arxiv.org/abs/1310.1531},
year = {2013}
}
@article{Dong2011,
abstract = {The co-evolution of social relationships and individual behavior in time and space has important implications, but is poorly understood because of the difficulty closely tracking the everyday life of a complete community. We offer evidence that relationships and behavior co-evolve in a student dormitory, based on monthly surveys and location tracking through resident cellular phones over a period of nine months. We demonstrate that a Markov jump process could capture the co-evolution in terms of the rates at which residents visit places and friends.},
author = {Dong, W. and Lepri, B. and Pentland, a.},
doi = {10.1145/2107596.2107613},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Dong, Lepri, Pentland - 2011 - Modeling the co-evolution of behaviors and social relationships using mobile phone data.pdf:pdf},
isbn = {9781450310963},
journal = {Proceedings of the 10th International Conference on Mobile and Ubiquitous Multimedia - MUM '11},
keywords = {human dynamics,living lab,social computing,stochastic process},
pages = {134--143},
title = {{Modeling the co-evolution of behaviors and social relationships using mobile phone data}},
url = {http://dl.acm.org/citation.cfm?doid=2107596.2107613},
year = {2011}
}
@article{Donoghue2010,
abstract = {Methods and tools for visualizing biological data have improved considerably over the last decades, but they are still inadequate for some high-throughput data sets. For most users, a key challenge is to benefit from the deluge of data without being overwhelmed by it. This challenge is still largely unfulfilled and will require the development of truly integrated and highly useable tools},
author = {Donoghue, Se\'{a}n I O and Gavin, Anne-claude and Gehlenborg, Nils and Goodsell, David S and H\'{e}rich\'{e}, Jean-karim and Nielsen, Cydney B and North, Chris and Olson, Arthur J and Procter, James B and Shattuck, David W and Walter, Thomas and Wong, Bang},
doi = {10.1038/nmeth0310-S2},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/nmeth.f.301.pdf:pdf},
issn = {1548-7091},
journal = {Nature Publishing Group},
number = {3s},
pages = {S2--S4},
pmid = {20195254},
publisher = {Nature Publishing Group},
title = {{Visualizing biological data — now and in the future}},
url = {http://dx.doi.org/10.1038/nmeth0310-S2},
volume = {7},
year = {2010}
}
@article{Dosovitskiy2014,
abstract = {We train a generative convolutional neural network which is able to generate images of objects given object type, viewpoint, and color. We train the network in a supervised manner on a dataset of rendered 3D chair models. Our experiments show that the network does not merely learn all images by heart, but rather finds a meaningful representation of a 3D chair model allowing it to assess the similarity of different chairs, interpolate between given viewpoints to generate the missing ones, or invent new chair styles by interpolating between chairs from the training set. We show that the network can be used to find correspondences between different chairs from the dataset, outperforming existing approaches on this task.},
archivePrefix = {arXiv},
arxivId = {1411.5928},
author = {Dosovitskiy, Alexey and Springenberg, Jost Tobias and Brox, Thomas},
eprint = {1411.5928},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/1411.5928v2.pdf:pdf},
title = {{Learning to Generate Chairs with Convolutional Neural Networks}},
url = {http://arxiv.org/abs/1411.5928},
year = {2014}
}
@article{Drummond2006,
abstract = {This paper introduces cost curves, a graphical technique for visualizing the per- formance (error rate or expected cost) of 2-class classifiers over the full range of possible class distributions and misclassification costs. Cost curves are shown to be superior to ROC curves for visualizing classifier performance for most purposes. This is because they visually support several crucial types of performance assessment that cannot be done easily withROC curves, such as showing confidence intervals on a classifier’s performance, and visualizing the statistical significance of the difference in performance of two classifiers.Asoftware tool supporting all the cost curve analysis described in this paper is available from the authors.},
author = {Drummond, Chris and Holte, Robert C.},
doi = {10.1007/s10994-006-8199-5},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/Visualising Methods for classifier performance.pdf:pdf},
isbn = {0885612515730565},
issn = {08856125},
journal = {Machine Learning},
keywords = {Classifiers,Machine learning,Performance evaluation,ROC curves},
number = {1},
pages = {95--130},
title = {{Cost curves: An improved method for visualizing classifier performance}},
volume = {65},
year = {2006}
}
@article{Duch2003,
abstract = { Neural networks are commonly regarded as black boxes performing incomprehensible functions. For classification problems networks provide maps from high dimensional feature space to K-dimensional image space. Images of training vector are projected on polygon vertices, providing visualization of network function. Such visualization may show the dynamics of learning, allow for comparison of different networks, display training vectors around which potential problems may arise, show differences due to regularization and optimization procedures, investigate stability of network classification under perturbation of original vectors, and place new data sample in relation to training data, allowing for estimation of confidence in classification of a given sample. An illustrative example for the three-class Wine data and five-class Satimage data is described. The visualization method proposed here is applicable to any black box system that provides continuous outputs.},
author = {Duch, W.},
doi = {10.1109/IJCNN.2003.1223669},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/03-coloring.pdf:pdf},
isbn = {0-7803-7898-9},
issn = {1098-7576},
journal = {Proceedings of the International Joint Conference on Neural Networks, 2003.},
title = {{Coloring black boxes: visualization of neural network decisions}},
volume = {3},
year = {2003}
}
@article{Duchi2011,
abstract = {We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efficient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms.},
archivePrefix = {arXiv},
arxivId = {arXiv:1103.4296v1},
author = {Duchi, John and Hazan, Elad and Singer, Yoram},
eprint = {arXiv:1103.4296v1},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/DuchiHaSi10.pdf:pdf},
isbn = {9780982252925},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {adaptivity,online learning,stochastic convex optimization,subgradient methods},
pages = {2121--2159},
title = {{Adaptive Subgradient Methods for Online Learning and Stochastic Optimization}},
url = {http://jmlr.org/papers/v12/duchi11a.html},
volume = {12},
year = {2011}
}
@article{Dumoulin,
archivePrefix = {arXiv},
arxivId = {arXiv:1506.00619v1},
author = {Dumoulin, Vincent and Warde-farley, David},
eprint = {arXiv:1506.00619v1},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/1506.00619.pdf:pdf},
keywords = {gpgpu,large-scale machine learning,neural networks},
pages = {1--5},
title = {{Blocks and Fuel : Frameworks for deep learning}}
}
@article{Elgammal,
archivePrefix = {arXiv},
arxivId = {arXiv:1506.00711v1},
author = {Elgammal, Ahmed and Saleh, Babak},
eprint = {arXiv:1506.00711v1},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/1506.00711v1.pdf:pdf},
pages = {1--23},
title = {{Quantifying Creativity in Art Networks ∗}}
}
@article{Engineering2004,
author = {Engineering, Computer},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/03-vishidd1.pdf:pdf},
issn = {03029743},
pages = {38--43},
title = {{Visualization of Hidden Node Activity in Neural Networks : I . Visualization Methods}},
year = {2004}
}
@article{Erhan2009,
abstract = {Deep architectures have demonstrated state-of-the-art results in a variety of settings, especially with vision datasets. Beyond the model definitions and the quantitative analyses, there is a need for qualitative comparisons of the solutions learned by various deep architectures. The goal of this paper is to find good qualitative interpretations of high level features represented by such models. To this end, we contrast and compare several techniques applied on Stacked Denoising Autoencoders and Deep Belief Networks, trained on several vision datasets. We show that, perhaps counter-intuitively, such interpretation is possible at the unit level, that it is simple to accomplish and that the results are consistent across various techniques. We hope that such techniques will allow researchers in deep architectures to understand more of how and why deep architectures work},
author = {Erhan, Dumitru and Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Erhan et al. - 2009 - Visualizing higher-layer features of a deep network.pdf:pdf},
journal = {Bernoulli},
number = {1341},
pages = {1--13},
title = {{Visualizing higher-layer features of a deep network}},
url = {http://igva2012.wikispaces.asu.edu/file/view/Erhan+2009+Visualizing+higher+layer+features+of+a+deep+network.pdf},
year = {2009}
}
@article{Erhan2010,
abstract = {Much recent research has been devoted to learning algorithms for deep architectures such as Deep Belief Networks and stacks of auto-encoder variants, with impressive results obtained in several areas, mostly on vision and language data sets. The best results obtained on supervised learning tasks involve an unsupervised learning component, usually in an unsupervised pre-training phase. Even though these new algorithms have enabled training deep models, many questions remain as to the nature of this difficult learning problem. The main question investigated here is the following: how does unsupervised pre-training work? Answering this questions is important if learning in deep architectures is to be further improved. We propose several explanatory hypotheses and test them through extensive simulations. We empirically show the influence of pre-training with respect to architecture depth, model capacity, and number of training examples. The experiments confirm and clarify the advantage of unsupervised pre-training. The results suggest that unsupervised pre-training guides the learning towards basins of attraction of minima that support better generalization from the training data set; the evidence from these results supports a regularization explanation for the effect of pre-training.},
archivePrefix = {arXiv},
arxivId = {arXiv:1206.5538v1},
author = {Erhan, Dumitru and Courville, Aaron and Vincent, Pascal},
doi = {10.1145/1756006.1756025},
eprint = {arXiv:1206.5538v1},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/erhan10a.pdf:pdf},
isbn = {1532-4435},
issn = {15324435},
journal = {Journal of Machine Learning Research},
pages = {625--660},
title = {{Why Does Unsupervised Pre-training Help Deep Learning ?}},
url = {http://portal.acm.org/citation.cfm?id=1756025},
volume = {11},
year = {2010}
}
@article{Fountas2011,
author = {Fountas, Z},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Fountas - 2011 - Spiking Neural Networks for Human-like Avatar Control in a Simulated Environment.pdf:pdf},
number = {September},
title = {{Spiking Neural Networks for Human-like Avatar Control in a Simulated Environment}},
url = {http://www.doc.ic.ac.uk/teaching/distinguished-projects/2011/z.fountas.pdf},
year = {2011}
}
@article{Fry2004,
abstract = {The ability to collect, store, and manage data is increasing quickly, but our ability to understand it remains constant. In an attempt to gain better understanding of data, fi elds such as information visualization, data mining and graphic design are employed, each solving an isolated part of the specifi c problem, but failing in a broader sense: there are too many unsolved problems in the visualization of complex data. As a solution, this dissertation proposes that the individual fi elds be brought together as part of a singular process titled Computational Information Design. This dissertation fi rst examines the individual pedagogies of design, information, and computation with a focus on how they support one another as parts of a combined methodology for the exploration, analysis, and representation of complex data. Next, in order to make the process accessible to a wider audience, a tool is introduced to simplify the computational process for beginners, and can be used as a sketch- ing platform by more advanced users. Finally, a series of examples show how the methodology and tool can be used to address a range of data problems, in particular, the human genome.},
author = {Fry, Benjamin Jotham},
doi = {10.1111/j.1468-3083.2010.03837.x},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/dissertation-110323c.pdf:pdf},
issn = {14683083},
journal = {SciencesNew York},
number = {May 1997},
pages = {170},
pmid = {20849441},
title = {{Computational Information Design}},
url = {http://portal.acm.org/citation.cfm?id=1037443},
volume = {Ph. D},
year = {2004}
}
@article{Garson1991,
address = {San Francisco, CA, USA},
author = {Garson, G David},
issn = {0888-3785},
journal = {AI Expert},
month = apr,
number = {4},
pages = {46--51},
publisher = {Miller Freeman, Inc.},
title = {{Interpreting Neural-network Connection Weights}},
url = {http://dl.acm.org/citation.cfm?id=129449.129452},
volume = {6},
year = {1991}
}
@article{Glorot2010,
abstract = {Whereas before 2006 it appears that deep multilayer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We ﬁrst observe the inﬂuence of the non-linear activations functions. We ﬁnd that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we ﬁnd that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We ﬁnd that a new non-linearity that saturates less can often be beneﬁcial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difﬁcult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence.},
author = {Glorot, Xavier and Bengio, Yoshua},
doi = {10.1.1.207.2059},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/glorot10a (1).pdf:pdf},
issn = {15324435},
journal = {Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS)},
pages = {249--256},
title = {{Understanding the difficulty of training deep feedforward neural networks}},
url = {http://machinelearning.wustl.edu/mlpapers/paper\_files/AISTATS2010\_GlorotB10.pdf},
volume = {9},
year = {2010}
}
@article{Glorot2011,
abstract = {While logistic sigmoid neurons are more biologically plausable that hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neurons are an even better model of biological neurons and yield equal or better performance than hyperbolic tangent networks in spite of the hard non-linearity and non-differentiability at zero, creating sparse representations with true zeros, which seem remarkably suitable for naturally sparse data. Even though they can take advantage of semi-supervised setups with extra-unlabelled data, deep rectifier networks can reach their best performance without requiring any unsupervised pre-training on purely supervised tasks with large labelled data sets. Hence, these results can be seen as a new milestone in the attempts at understanding the difficulty in training deep but purely supervised nueral networks, and closing the performance gap between neural networks learnt with and without unsupervised pre-training},
author = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
doi = {10.1.1.208.6449},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/glorot11a.pdf:pdf},
issn = {15324435},
journal = {Proceedings of the 14th International Conference on Artificial Intelligence and Statisitics (AISTATS) 2011},
pages = {315--323},
title = {{Deep Sparse Rectifier Neural Networks}},
volume = {15},
year = {2011}
}
@article{Goebel1999,
abstract = {Abstract Knowledge discovery in databases is a rapidly growing field, whose development is driven by strong research interests as well as urgent practical, social, and economical needs. While the last few years knowledge discovery tools have been used mainly in ... },
author = {Goebel, Michael and Gruenwald, Le},
doi = {10.1145/846170.846172},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/survey-datamining.pdf:pdf},
isbn = {978-3-540-41089-8},
issn = {19310145},
journal = {ACM SIGKDD Explorations Newsletter},
keywords = {data mining,knowledge discovery in databases,surveys},
number = {1},
pages = {20--33},
title = {{A survey of data mining and knowledge discovery software tools}},
volume = {1},
year = {1999}
}
@article{Goh1995,
abstract = {In complex engineering systems, empirical relationships are often employed to estimate design parameters and engineering properties. A complex domain is characterized by a number of interacting factors and their relationships are, in general, not precisely known. In addition, the data associated with these parameters are usually incomplete or erroneous (noisy). The development of these empirical relationships is a formidable task requiring sophisticated modeling techniques as well as human intuition and experience. This paper demonstrates the use of back-propagation neural networks to alleviate this problem. Backpropagation neural networks are a product of artificial intelligence research. First, an overview of the neural network methodology is presented. This is followed by some practical guidelines for implementing back-propagation neural networks. Two examples are then presented to demonstrate the potential of this approach for capturing nonlinear interactions between variables in complex engineering systems.},
author = {a.T.C. Goh},
doi = {10.1016/0954-1810(94)00011-S},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/1-s2.0-095418109400011S-main.pdf:pdf},
isbn = {0954-1810},
issn = {09541810},
journal = {Artificial Intelligence in Engineering},
keywords = {back propagation,cal engineering,complex systems,cone penetration,modeling,neural networks,pile driving},
number = {3},
pages = {143--151},
title = {{Back-propagation neural networks for modeling complex systems}},
volume = {9},
year = {1995}
}
@article{Goodfellow2015,
abstract = {Training neural networks involves solving large-scale non-convex optimization problems. This task has long been believed to be extremely difficult, with fear of local minima and other obstacles motivating a variety of schemes to improve opti-mization, such as unsupervised pretraining. However, modern neural networks are able to achieve negligible training error on complex tasks, using only direct train-ing with stochastic gradient descent. We introduce a simple analysis technique to look for evidence that such networks are overcoming local optima. We find that, in fact, on a straight path from initialization to solution, a variety of state of the art neural networks never encounter any significant obstacles.},
archivePrefix = {arXiv},
arxivId = {arXiv:1412.6544v5},
author = {Goodfellow, Ian J. and Vinyals, Oriol and Saxe, Andrew M.},
eprint = {arXiv:1412.6544v5},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/1412.6544v5.pdf:pdf},
journal = {To appear: ICLR-2015},
pages = {1--11},
title = {{Qualitatively characterizing neural network optimization problems}},
url = {http://arxiv.org/abs/1412.6544},
year = {2015}
}
@article{Graves2013,
abstract = {This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.},
archivePrefix = {arXiv},
arxivId = {arXiv:1308.0850v5},
author = {Graves, Alex},
eprint = {arXiv:1308.0850v5},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/1308.0850v5.pdf:pdf},
journal = {arXiv preprint arXiv:1308.0850},
pages = {1--43},
title = {{Generating sequences with recurrent neural networks}},
url = {http://arxiv.org/abs/1308.0850},
year = {2013}
}
@article{Graves2014,
author = {Graves, Alex and Jaitly, N},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/graves14.pdf:pdf},
journal = {JMLR Workshop and Conference Proceedings},
number = {1},
pages = {1764--1772},
title = {{Towards End-To-End Speech Recognition with Recurrent Neural Networks}},
url = {http://jmlr.org/proceedings/papers/v32/graves14.pdf},
volume = {32},
year = {2014}
}
@article{Gregor2014,
abstract = {This paper introduces the Deep Recurrent Atten-tive Writer (DRAW) neural network architecture for image generation. DRAW networks combine a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto-encoding framework that allows for the iterative construction of complex images. The system substantially improves on the state of the art for generative models on MNIST, and, when trained on the Street View House Numbers dataset, it generates images that cannot be distin-guished from real data with the naked eye.},
archivePrefix = {arXiv},
arxivId = {arXiv:1502.04623v2},
author = {Gregor, Karol and Danihelka, Ivo and Graves, Alex and {Jimenez Rezende}, Danilo and Wierstra, Daan},
eprint = {arXiv:1502.04623v2},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/1502.04623v2.pdf:pdf},
title = {{DRAW: A Recurrent Neural Network For Image Generation}},
year = {2014}
}
@article{Grimmer2014,
author = {Grimmer, Justin},
doi = {10.1017/S1049096514001784},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Grimmer - 2014 - We ’ re All Social Scientists Now How Big Data , Machine Learning , and Causal Inference Work Together.pdf:pdf},
issn = {15375935},
pages = {1--8},
title = {{We ’ re All Social Scientists Now : How Big Data , Machine Learning , and Causal Inference Work Together}},
year = {2014}
}
@article{Hansen2009,
abstract = {The last decades of the twentieth century have witnessed, as part of the second demographic transition affecting most industrial countries (Van de Kaa, 1987), two features of particular interest here – a delay in entry to motherhood and an increased chance of women being employed even after they have children. In Britain, these trends have not been experienced uniformly across the social spectrum. The research reported in this chapter attempts to establish links between these two phenomena, to quantify the extent of social differentials (in the timing of first motherhood and maternal employment) and to investigate their impact on the development of children},
author = {Hansen, Kirstine and Hawkes, Denise and Joshi, Heather},
doi = {10.1007/978-1-4020-9682-2\_4},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/4th\_paradigm\_book\_part3\_hansen\_johnson.pdf:pdf},
isbn = {978-1-4020-9682-2},
keywords = {HB Economic Theory,HD Industries. Land use. Labor},
pages = {153--163},
title = {{The timing of motherhood, mothers’ employment and child outcomes}},
url = {http://dx.doi.org/10.1007/978-1-4020-9682-2\_4},
year = {2009}
}
@article{Hansen2002,
author = {Hansen, Steven and Narayanan, Hari and Hegarty, Mary},
doi = {10.1006/S1045-926X(02)00027-7},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/1-s2.0-S1045926X02902363-main.pdf:pdf},
issn = {1045926X},
journal = {Journal of Visual Languages and Computing},
keywords = {algorithms,animation,empirical evaluation,learning,visualization},
number = {3},
pages = {291--317},
title = {{Designing Educationally Effective AlgorithmVisualizations}},
volume = {13},
year = {2002}
}
@article{Hassabis2012,
abstract = {To celebrate the centenary of the year of Alan Turing’s birth, four scientists and entrepreneurs assess the divide between neuroscience and computing},
author = {Hassabis, Demis and Brooks, Rodney},
doi = {10.1038/482462a},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/TuringSpecialIssue(Nature2012).pdf:pdf},
isbn = {1476-4687 (Electronic)$\backslash$n0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
number = {7386},
pages = {462--463},
pmid = {22358812},
title = {{Turing centenary: Is the brain a good model for machine intelligence?}},
volume = {482},
year = {2012}
}
@article{Heer2007,
abstract = {Information visualization leverages the human visual system to support the process of sensemaking, in which information is collected, organized, and analyzed to generate knowledge and inform action. Though most research to date assumes a single-user focus on perceptual and cognitive processes, in practice, sensemaking is often a social process involving parallelization of effort, discussion, and consensus building. This suggests that to fully support sensemaking, interactive visualization should also support social interaction. However, the most appropriate collaboration mechanisms for supporting this interaction are not immediately clear. In this article, we present design considerations for asynchronous collaboration in visual analysis environments, highlighting issues of work parallelization, communication, and social organization. These considerations provide a guide for the design and evaluation of collaborative visualization systems.},
author = {Heer, Jeffrey and Agrawala, Maneesh},
doi = {10.1109/VAST.2007.4389011},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/2008-DesignCollabVis-IVS.pdf:pdf},
isbn = {9781424416592},
issn = {1473-8716},
journal = {VAST IEEE Symposium on Visual Analytics Science and Technology 2007, Proceedings},
keywords = {Analysis,Collaboration,Computer-supported cooperative work,Design,Visualization},
number = {December 2007},
pages = {171--178},
title = {{Design considerations for collaborative visual analytics}},
year = {2007}
}
@article{Heer2008,
abstract = {Interactive history tools, ranging from basic undo and redo to branching timelines of user actions, facilitate iterative forms of interaction. In this paper, we investigate the design of history mechanisms for information visualization. We present a design space analysis of both architectural and interface issues, identifying design decisions and associated trade-offs. Based on this analysis, we contribute a design study of graphical history tools for Tableau, a database visualization system. These tools record and visualize interaction histories, support data analysis and communication of findings, and contribute novel mechanisms for presenting, managing, and exporting histories. Furthermore, we have analyzed aggregated collections of history sessions to evaluate Tableau usage. We describe additional tools for analyzing users' history logs and how they have been applied to study usage patterns in Tableau.},
author = {Heer, Jeffrey and Mackinlay, Jock D. and Stolte, Chris and Agrawala, Maneesh},
doi = {10.1109/TVCG.2008.137},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/2008-GraphicalHistories-InfoVis.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Analysis,Evaluation,History,Presentation,Undo,Visualization},
number = {6},
pages = {1189--1196},
pmid = {18988963},
title = {{Graphical histories for visualization: Supporting analysis, communication, and evaluation}},
volume = {14},
year = {2008}
}
@article{Heer2011,
abstract = {The study of complex activities such as scientific production and software development often require modeling connections among heterogeneous entities including people, institutions and artifacts. Despite numerous advances in algorithms and visualization techniques for understanding such social networks, the process of constructing network models and performing exploratory analysis remains difficult and time-consuming. In this paper we present Orion, a system for interactive modeling, transformation and visualization of network data. Orion's interface enables the rapid manipulation of large graphs-including the specification of complex linking relationships-using simple drag-and-drop operations with desired node types. Orion maps these user interactions to statements in a declarative workflow language that incorporates both relational operators (e.g., selection, aggregation and joins) and network analytics (e.g., centrality measures). We demonstrate how these features enable analysts to flexibly construct and compare networks in domains such as online health communities, academic collaboration and distributed software development.},
author = {Heer, Jeffrey and Perer, Adam},
doi = {10.1109/VAST.2011.6102441},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/2011-Orion-VAST.pdf:pdf},
isbn = {9781467300131},
issn = {1473-8716},
journal = {VAST 2011 - IEEE Conference on Visual Analytics Science and Technology 2011, Proceedings},
keywords = {data management,data transformation,end-user programming,graphs,social network analysis,visualization},
pages = {51--60},
title = {{Orion: A system for modeling, transformation and visualization of multidimensional heterogeneous networks}},
year = {2011}
}
@article{Herman2000,
abstract = {This is a survey on graph visualization and navigation techniques,$\backslash$nas used in information visualization. Graphs appear in numerous$\backslash$napplications such as Web browsing, state-transition diagrams, and data$\backslash$nstructures. The ability to visualize and to navigate in these$\backslash$npotentially large, abstract graphs is often a crucial part of an$\backslash$napplication. Information visualization has specific requirements, which$\backslash$nmeans that this survey approaches the results of traditional graph$\backslash$ndrawing from a different perspective},
author = {Herman, I. and Melancon, G. and Marshall, M.S.},
doi = {10.1109/2945.841119},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/00841119.pdf:pdf},
isbn = {1077-2626 VO - 6},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {1},
pages = {1--21},
pmid = {841119},
title = {{Graph visualization and navigation in information visualization: A$\backslash$nsurvey}},
volume = {6},
year = {2000}
}
@article{Hermans2013a,
abstract = {Time series often have a temporal hierarchy, with information that is spread out over multiple time scales. Common recurrent neural networks, however, do not explicitly accommodate such a hierarchy, and most research on them has been focusing on training algorithms rather than on their basic architecture. In this pa- per we study the effect of a hierarchy of recurrent neural networks on processing time series. Here, each layer is a recurrent network which receives the hidden state of the previous layer as input. This architecture allows us to perform hi- erarchical processing on difficult temporal tasks, and more naturally capture the structure of time series. We show that they reach state-of-the-art performance for recurrent networks in character-level language modeling when trained with sim- ple stochastic gradient descent. We also offer an analysis of the different emergent time scales.},
author = {Hermans, Michiel and Schrauwen, Benjamin},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/5166-training-and-analysing-deep-recurrent-neural-networks.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
keywords = {Recurrent Neural Networks},
pages = {190--198},
title = {{Training and Analyzing Deep Recurrent Neural Networks}},
year = {2013}
}
@article{Hermans2013,
author = {Hermans, Michiel and Schrauwen, Benjamin},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/NIPS2013\_5166.pdf:pdf},
journal = {\ldots Neural Information Processing Systems},
pages = {1--9},
title = {{Training and Analysing Deep Recurrent Neural Networks}},
url = {http://papers.nips.cc/paper/5166-training-and-analysing-deep-recurrent-neural-networks},
year = {2013}
}
@article{Hertzmann2003,
abstract = { It is argued that computer graphics can benefit from a deeper use of machine learning techniques. The author gives an overview of what learning has to offer the graphics community, with an emphasis on Bayesian techniques. He also attempts to address some misconceptions about learning, and to give a very brief tutorial on Bayesian reasoning.},
author = {Hertzmann, a.},
doi = {10.1109/PCCGA.2003.1238242},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Hertzmann - 2003 - Machine learning for computer graphics a manifesto and tutorial.pdf:pdf},
isbn = {0-7695-2028-6},
issn = {0769520286},
journal = {11th Pacific Conference onComputer Graphics and Applications, 2003. Proceedings.},
title = {{Machine learning for computer graphics: a manifesto and tutorial}},
year = {2003}
}
@article{Hill2012,
author = {Hill, Mcgraw},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Hill - 2012 - Notes on Multilayer , Feedforward Neural Networks Fall 2012.pdf:pdf},
pages = {1--7},
title = {{Notes on Multilayer , Feedforward Neural Networks Fall 2012}},
year = {2012}
}
@article{Hinton2010,
abstract = {(by JL)Les recettes de cuisine de Hinton!Pas de d\'{e}tour par la th\'{e}orie, mais Hinton livre ses intuitions et son exp\'{e}rience.Des conseils pratiques sur comment entrainer les r\'{e}seaux, et comment v\'{e}rifier que l'entrainement se passe bien (notamment, des conseils pour la visualisation de ce qui se passe...).},
author = {Hinton, Geoffrey},
doi = {10.1007/978-3-642-35289-8\_32},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/guideTR.pdf:pdf},
isbn = {978-3-642-35288-1},
issn = {364235288X},
journal = {Computer},
number = {3},
pages = {1},
title = {{A Practical Guide to Training Restricted Boltzmann Machines A Practical Guide to Training Restricted Boltzmann Machines}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.170.9573\&amp;rep=rep1\&amp;type=pdf},
volume = {9},
year = {2010}
}
@article{Hinton2014,
abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different “thinned” networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets},
author = {Hinton, Geoffrey},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/srivastava14a.pdf:pdf},
isbn = {1532-4435},
issn = {15337928},
journal = {Journal of Machine Learning Research (JMLR)},
keywords = {deep learning,model combination,neural networks,regularization},
pages = {1929--1958},
title = {{Dropout : A Simple Way to Prevent Neural Networks from Overfitting}},
volume = {15},
year = {2014}
}
@article{Hinton2013,
author = {Hinton, Geoffrey},
journal = {Coursera},
title = {{Neural Networks for Machine Learning}},
url = {https://www.coursera.org/course/neuralnets},
year = {2013}
}
@misc{Hinton1986,
abstract = {Concepts can be represented by distributed patterns of activity in networks of neuron-like units. One advantage of this kind of representation is that it leads to automatic generalization. When the weighjts in the network are changed to incorporate new knowledgwe about one concept, the changes affect the knowledge associated with other concepts that are represented by similar activity patterns. There have been numerous demonstrations of sensible generalization which have depended on the experimenter choosing appropriately similar patterns for diferent concepts. This paper shows how the network can be made to choose the patterns itself when shown a set of propositions that use the concepts. It chooses patterns which make explicit the underlying features that are only implicit in the propositions it is shown.},
author = {Hinton, Geoffrey E.},
booktitle = {Proceedings of the eighth annual conference of the Cognitive Science Society},
doi = {10.1109/69.917563},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/hinton86.pdf:pdf},
pages = {1--12},
title = {{Learning distributed representations of concepts}},
url = {http://www.cogsci.ucsd.edu/~ajyu/Teaching/Cogs202\_sp13/Readings/hinton86.pdf},
year = {1986}
}
@article{Hinton2012,
abstract = {When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This "overfitting" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random "dropout" gives big improvements on many benchmark tasks and sets new records for speech and object recognition.},
archivePrefix = {arXiv},
arxivId = {1207.0580},
author = {Hinton, Geoffrey E. and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R.},
doi = {arXiv:1207.0580},
eprint = {1207.0580},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/1207.0580v1.pdf:pdf},
journal = {arXiv: 1207.0580},
pages = {1--18},
title = {{Improving neural networks by preventing co-adaptation of feature detectors}},
url = {http://arxiv.org/abs/1207.0580},
year = {2012}
}
@article{Hinton2002,
author = {Hinton, Geoffrey and Roweis, Sam},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/2276-stochastic-neighbor-embedding.pdf:pdf},
title = {{Stochastic Neighbor Embedding}},
year = {2002}
}
@article{Hoffman1999,
author = {Hoffman, Patrick},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/tablevizx.pdf:pdf},
title = {{Table Visualization: A formal model and its applications}},
year = {1999}
}
@article{Hotelling33,
author = {Hotelling, H},
journal = {J. Educ. Psych.},
keywords = {pca},
title = {{Analysis of a complex of statistical variables into principal components}},
volume = {24},
year = {1933}
}
@article{Iliinsky2013,
author = {Iliinsky, By Noah},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/YTW03323USEN (1).pdf:pdf},
pages = {12},
title = {{Choosing visual properties for successful visualizations}},
year = {2013}
}
@article{Iliinsky2006,
author = {Iliinsky, Noah},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/iliinsky\_complex\_diagrams.pdf:pdf},
journal = {Communication},
title = {{Generation of Complex Diagrams: How to Make Lasagna Instead of Spaghetti}},
year = {2006}
}
@article{Iliinsky2012,
author = {Iliinsky, Noah},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/VisualPropertiesTable.pdf:pdf},
pages = {2012},
title = {{Properties and Best Uses of Visual Encodings}},
year = {2012}
}
@article{IntelITCenter2013,
author = {{Intel IT Center}},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/big-data-visualization-turning-big-data-into-big-insights.pdf:pdf},
journal = {White Paper on Big Data Visualization [White Paper]},
number = {March},
title = {{Big Data Visualization : Turning Big Data Into Big Insights}},
url = {http://www.intel.com/content/dam/www/public/us/en/documents/white-papers/big-data-visualization-turning-big-data-into-big-insights.pdf},
year = {2013}
}
@article{Ioffe2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1502.03167v3},
author = {Ioffe, Sergey and Szegedy, Christian},
eprint = {arXiv:1502.03167v3},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/1502.03167v3.pdf:pdf},
journal = {arXiv preprint arXiv:1502.03167v3},
title = {{Batch Normalization : Accelerating Deep Network Training by Reducing Internal Covariate Shift}},
year = {2015}
}
@article{JamesBooth2012,
author = {{James Booth}},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/James Booth - 2012 - Constructing 3D Morphable Facial Models capable of expressing emotion.pdf:pdf},
number = {September},
title = {{Constructing 3D Morphable Facial Models capable of expressing emotion}},
year = {2012}
}
@article{Jarrett2009,
abstract = {In many recent object recognition systems, feature extraction stages are generally composed of a filter bank, a non-linear transformation, and some sort of feature pooling layer. Most systems use only one stage of feature extraction in which the filters are hard-wired, or two stages where the filters in one or both stages are learned in supervised or unsupervised mode. This paper addresses three questions: 1. How does the non-linearities that follow the filter banks influence the recognition accuracy? 2. does learning the filter banks in an unsupervised or supervised manner improve the performance over random filters or hardwired filters? 3. Is there any advantage to using an architecture with two stages of feature extraction, rather than one? We show that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks. We show that two stages of feature extraction yield better accuracy than one. Most surprisingly, we show that a two-stage system with random filters can yield almost 63\% recognition rate on Caltech-101, provided that the proper non-linearities and pooling layers are used. Finally, we show that with supervised refinement, the system achieves state-of-the-art performance on NORB dataset (5.6\%) and unsupervised pre-training followed by supervised refinement produces good accuracy on Caltech-101 (\&amp;gt; 65\%), and the lowest known error rate on the undistorted, unprocessed MNIST dataset (0.53\%).},
author = {Jarrett, Kevin and Kavukcuoglu, Koray and Ranzato, Marc'Aurelio and LeCun, Yann},
doi = {10.1109/ICCV.2009.5459469},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/jarrett-iccv-09.pdf:pdf},
isbn = {9781424444205},
issn = {1550-5499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {2146--2153},
title = {{What is the best multi-stage architecture for object recognition?}},
year = {2009}
}
@article{Jiang2010,
author = {Jiang, Lu and Wu, Zhaohui and Feng, Qian and Liu, Jun and Zheng, Qinghua},
doi = {10.1007/978-3-642-13657-3\_46},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Jiang et al. - 2010 - Efficient deep web crawling using reinforcement learning.pdf:pdf},
isbn = {3642136567},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Deep web crawling,Hidden web,Reinforcement learning},
number = {PART 1},
pages = {428--439},
title = {{Efficient deep web crawling using reinforcement learning}},
volume = {6118 LNAI},
year = {2010}
}
@article{Kairam2012,
abstract = {ABSTRACT Visual methods for supporting the characterization, comparison, and classification of large networks remain an open challenge. Ideally, such techniques should surface useful structural features–such as effective diameter, small-world properties, and ... $\backslash$n},
author = {Kairam, Sanjay and MacLean, Diana and Savva, Manolis and Heer, Jeffrey},
doi = {10.1145/2254556.2254651},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/2012-GraphPrism-AVI.pdf:pdf},
isbn = {9781450312875},
journal = {International Conference on Advanced Visual Interfaces (AVI)},
keywords = {graph visualization,network analysis,scalability},
pages = {498},
title = {{GraphPrism: Compact Visualization of Network Structure}},
url = {http://dl.acm.org/citation.cfm?doid=2254556.2254651},
year = {2012}
}
@article{Karpathy2014b,
author = {Karpathy, Andrej},
title = {{Visualizing Top Tweeps with t-SNE, in Javascript}},
url = {http://karpathy.github.io/2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/},
year = {2014}
}
@article{Karpathy2014,
author = {Karpathy, Andrej},
title = {{Hacker's guide to Neural Networks}},
url = {http://karpathy.github.io/neuralnets/},
year = {2014}
}
@article{Karpathy2015,
author = {Karpathy, Andrej},
title = {{The Unreasonable Effectiveness of Recurrent Neural Networks}},
url = {http://karpathy.github.io/2015/05/21/rnn-effectiveness/},
year = {2015}
}
@article{Karpathy2015a,
author = {Karpathy, Andrej},
title = {{Breaking Linear Classifiers on ImageNet}},
url = {http://karpathy.github.io/2015/03/30/breaking-convnets/},
year = {2015}
}
@article{Karpathy2014a,
author = {Karpathy, Andrej},
title = {{ConvNetJS: Deep Learning in your browser}},
url = {http://cs.stanford.edu/people/karpathy/convnetjs/},
year = {2014}
}
@misc{Karpathy2015b,
author = {Karpathy, Andrej and Li, Fei-Fei},
title = {{Stanford University CS231n: Convolutional Neural Networks for Visual Recognition}},
url = {http://cs231n.stanford.edu/syllabus.html},
urldate = {2015-06-08},
year = {2015}
}
@article{Keim2002,
author = {Keim, D a},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/ieee vis.pdf:pdf},
isbn = {1077-2626},
journal = {IEEE Trans Vis Comput Graph},
keywords = {data mining,data type,data visualisation,distortion technique,information visualization,interaction technique,visual data exploration,visual data mining},
number = {1},
pages = {1--8},
title = {{Information visualization and visual data mining}},
volume = {8},
year = {2002}
}
@article{Keim2000,
author = {Keim, Daniel A},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/163.pdf:pdf},
number = {1},
pages = {1--20},
title = {{Designing Pixel-Oriented Visualization Techniques : Theory and Applications}},
volume = {6},
year = {2000}
}
@article{Kelly2011,
abstract = {Wise management of electricity consumption is becoming increasingly important. Domestic electricity prices in the UK increased by 35 \% over the past 8 years; an upward trend which is unlikely to reverse any time soon. As well as the economic costs, the environmental problems associated with the combustion of fossil fuels are becoming increasingly detrimental to the well-being of many species, including our own. One of the cheapest and easiest ways to improve energy efficiency is to monitor one's electricity consumption using a type of smart meter called a “home energy monitor” available for around £40. These display whole-house consumption in real-time, allowing the user to learn which devices and behaviours consume the most energy. Studies have demonstrated that the feedback provided by energy monitors can enable users to reduce consumption by 5-15 \%. If every domestic user in the UK reduced electricity consumption by 10 \% then the UK's annual CO2 output would be reduced by 6 million tonnes. However, the information displayed by home energy monitors is not as useful as it could be. Home energy monitors measure aggregate consumption for an entire building. Research has demonstrated that disaggregated information describing appliance-by-appliance energy consumption is more effective than aggregate information. Disaggregation was first successfully implemented in the 1980s using sophisticated smart meters which provide rich, multi-dimensional raw sensor data. However, these sophisticated meters are not readily available at present. The main contribution of this project is to design, implement and evaluate three different algorithms for disaggregating the sparse, one-dimensional data output by inexpensive, popular and readily available home energy monitors. Each design is trained to recognise a device on the basis of one or more raw recordings of single-device power consumption (which we call signatures). The system is then given an unseen aggregate signal from which it must infer the start times, run duration and energy consumption of each device activation present in the aggregate data. The first design is a simple prototype which uses a least mean squares approach to matching a signature to an aggregate signal. As expected, this design succeeds only in a very limited set of contexts but the development of this prototype provided valuable insights. The second design represents a novel approach to determining a set of device power states by identifying peaks in the histogram of the device's signature but this design proved to not be ideal. The final design presented in this dissertation represents a novel approach to disaggregation whereby each device is modelled as a power state graph. Each graph vertex (node) represents a power state and each edge represents the conditions necessary to transition from the source to the destination power state. During disaggregation, every possible “fit” of the power state graph to the aggregate data is represented as a tree structure where each tree vertex represents a power state and each tree edge represents the likelihood for the corresponding power state transition. For each complete “fit” of the power state graph to the aggregate data, the disaggregation algorithm reports the start time, the average likelihood, the estimated run time and the estimated total energy consumption. This design has several attractive features: 1) it handles both simple devices and complex devices whose signatures contain power state sequences which repeat an arbitrary number of times; 2) it is probabilistic; 3) a power state graph can be learnt from one or more signatures and 4) the design estimates the energy consumed by each device activation. This design was evaluated by training it to recognise four real devices: a toaster, a kettle, a washing machine and a tumble drier. The system was then given 13 days of real aggregate data. For all devices except the tumble drier it detected every device activation in the aggregate data although there were a few false positives. The system failed to model the tumble drier, possibly because the drier has very rapid state transitions.},
author = {Kelly, Jack},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Kelly - 2011 - Disaggregating Smart Meter Readings using Device Signatures.pdf:pdf},
number = {September},
title = {{Disaggregating Smart Meter Readings using Device Signatures}},
url = {http://www.doc.ic.ac.uk/teaching/distinguished-projects/2011/d.kelly.pdf},
year = {2011}
}
@article{King2010,
author = {King, Harriet},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/HKing\_ValueCasualInfoVis.pdf:pdf},
journal = {Data Visualization},
number = {December},
title = {{Exploring the Value of Casual Infovis}},
url = {http://www.csl.mtu.edu/~hcking/HKing\_ValueCasualInfoVis.pdf},
year = {2010}
}
@article{Krizhevsky2012,
archivePrefix = {arXiv},
arxivId = {1102.0183},
author = {Krizhevsky, a and Sutskever, I and Hinton, Ge},
eprint = {1102.0183},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/imagenet.pdf:pdf},
isbn = {9781627480031},
issn = {10495258},
journal = {Advances in neural information processing systems},
pages = {1097--1105},
title = {{Imagenet classification with deep convolutional neural networks}},
year = {2012}
}
@article{Kurek2013a,
author = {Kurek, Maciej and Becker, Tobias and Luk, Wayne},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Kurek, Becker, Luk - 2013 - Parametric optimization of reconfigurable designs using machine learning.pdf:pdf},
journal = {Reconfigurable Computing: Architectures, \ldots},
keywords = {fpga,gp,optimization,pso,surrogate modeling,svm},
pages = {134--145},
title = {{Parametric optimization of reconfigurable designs using machine learning}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-36812-7\_13},
year = {2013}
}
@article{Kurek2012,
author = {Kurek, MacIej and Luk, Wayne},
doi = {10.1109/FPT.2012.6412120},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Kurek, Luk - 2012 - Parametric reconfigurable designs with Machine Learning Optimizer.pdf:pdf},
isbn = {9781467328449},
journal = {FPT 2012 - 2012 International Conference on Field-Programmable Technology},
pages = {109--112},
title = {{Parametric reconfigurable designs with Machine Learning Optimizer}},
year = {2012}
}
@article{Kurek2013,
author = {Kurek, Maciej and Luk, Wayne},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Kurek, Luk - 2013 - MULTI-OBJECTIVE SELF-OPTIMIZATION OF RECONFIGURABLE DESIGNS WITH MACHINE LEARNING Maciej Kurek , Tianchi Liu , W.pdf:pdf},
keywords = {designs with,ti-objective self-optimization of reconfigurable},
title = {{MULTI-OBJECTIVE SELF-OPTIMIZATION OF RECONFIGURABLE DESIGNS WITH MACHINE LEARNING Maciej Kurek , Tianchi Liu , Wayne Luk ∗ Department of Computing Imperial College London 180 Queen ’ s Gate , London SW7 2BZ , England}},
year = {2013}
}
@article{Larochelle2009,
abstract = {Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization often appears to get stuck in poor solutions. Hinton et al. recently proposed a greedy layer-wise unsupervised learning procedure relying on the training algorithm of restricted Boltzmann machines (RBM) to initialize the parameters of a deep belief network (DBN), a generative model with many layers of hidden causal variables. This was followed by the proposal of another greedy layer-wise procedure, relying on the usage of autoassociator networks. In the context of the above optimization problem, we study these algorithms empirically to better understand their success. Our experiments confirm the hypothesis that the greedy layer-wise unsupervised training strategy helps the optimization by initializing weights in a region near a good local minimum, but also implicitly acts as a sort of regularization that brings better generalization and encourages internal distributed representations that are high-level abstractions of the input. We also present a series of experiments aimed at evaluating the link between the performance of deep neural networks and practical aspects of their topology, for example, demonstrating cases where the addition of more depth helps. Finally, we empirically explore simple variants of these training algorithms, such as the use of different RBM input unit distributions, a simple way of combining gradient estimators to improve performance, as well as on-line versions of those algorithms. },
author = {Larochelle, Hugo and Larochelle, Hugo and Bengio, Yoshua and Bengio, Yoshua and Lourador, Jerome and Lourador, Jerome and Lamblin, Pascal and Lamblin, Pascal},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/jmlr-larochelle09a.pdf:pdf},
isbn = {3531207857},
issn = {15324435},
journal = {Journal of Machine Learning Research},
pages = {1--40},
title = {{Exploring Strategies for Training Deep Neural Networks}},
volume = {10},
year = {2009}
}
@article{Lazebnik2014,
abstract = {Lecture @ University of Illinois at Urbana-Champaign},
author = {Lazebnik, Svetlana},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/http-$\backslash$:$\backslash$:web.engr.illinois.edu$\backslash$:\~{}slazebni$\backslash$:spring14$\backslash$:lec24\_cnn.pdf:pdf},
title = {{Deep Convolutional Neural Networks for Image Classification}},
url = {http://www.cs.illinois.edu/~slazebni/spring14/},
year = {2014}
}
@article{Le2010,
abstract = {Convolutional neural networks (CNNs) have been successfully applied to many tasks such as digit and object recognition. Using convolutional (tied) weights significantly reduces the number of parameters that have to be learned, and also allows translational invariance to be hard-coded into the architecture. In this pa- per, we consider the problem of learning invariances, rather than relying on hard- coding. We propose tiled convolution neural networks (Tiled CNNs), which use a regular “tiled” pattern of tied weights that does not require that adjacent hidden units share identical weights, but instead requires only that hidden units k steps away from each other to have tied weights. By pooling over neighboring units, this architecture is able to learn complex invariances (such as scale and rotational invariance) beyond translational invariance. Further, it also enjoysmuch ofCNNs’ advantage of having a relatively small number of learned parameters (such as ease of learning and greater scalability). We provide an efficient learning algorithm for Tiled CNNs based on Topographic ICA, and show that learning complex invariant features allows us to achieve highly competitive results for both the NORB and CIFAR-10 datasets.},
author = {Le, Quoc V and Ngiam, Jiquan and Chen, Zhenghao and Chia, Daniel and Koh, Pang Wei and Ng, Andrew Y},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/nips10-TiledConvolutionalNeuralNetworks.pdf:pdf},
journal = {Advances in Neural Information Processing Systems 23},
pages = {1279--1287},
title = {{Tiled convolutional neural networks}},
year = {2010}
}
@article{Le2011,
abstract = {We consider the problem of building high- level, class-specific feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images? To answer this, we train a 9-layered locally connected sparse autoencoder with pooling and local contrast normalization on a large dataset of images (the model has 1 bil- lion connections, the dataset has 10 million 200x200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous SGD on a clus- ter with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental re- sults reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also find that the same network is sensitive to other high-level concepts such as cat faces and human bod- ies. Starting with these learned features, we trained our network to obtain 15.8\% accu- racy in recognizing 20,000 object categories from ImageNet, a leap of 70\% relative im- provement over the previous state-of-the-art.},
archivePrefix = {arXiv},
arxivId = {1112.6209},
author = {Le, Quoc V. and Ranzato, Marc'Aurelio and Monga, Rajat and Devin, Matthieu and Chen, Kai and Corrado, Greg S. and Dean, Jeff and Ng, Andrew Y.},
eprint = {1112.6209},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/unsupervised\_icml2012.pdf:pdf},
keywords = {unsupervised learning, deep learning},
title = {{Building high-level features using large scale unsupervised learning}},
url = {http://arxiv.org/abs/1112.6209},
year = {2011}
}
@misc{LeCun1989,
abstract = {The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the US Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification.},
author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
booktitle = {Neural Computation},
doi = {10.1162/neco.1989.1.4.541},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/lecun-89e.pdf:pdf},
issn = {0899-7667},
number = {4},
pages = {541--551},
title = {{Backpropagation Applied to Handwritten Zip Code Recognition}},
volume = {1},
year = {1989}
}
@article{LeCun1998,
abstract = {Multilayer neural networks trained with the back-propagation
algorithm constitute the best example of a successful gradient based
learning technique. Given an appropriate network architecture,
gradient-based learning algorithms can be used to synthesize a complex
decision surface that can classify high-dimensional patterns, such as
handwritten characters, with minimal preprocessing. This paper reviews
various methods applied to handwritten character recognition and
compares them on a standard handwritten digit recognition task.
Convolutional neural networks, which are specifically designed to deal
with the variability of 2D shapes, are shown to outperform all other
techniques. Real-life document recognition systems are composed of
multiple modules including field extraction, segmentation recognition,
and language modeling. A new learning paradigm, called graph transformer
networks (GTN), allows such multimodule systems to be trained globally
using gradient-based methods so as to minimize an overall performance
measure. Two systems for online handwriting recognition are described.
Experiments demonstrate the advantage of global training, and the
flexibility of graph transformer networks. A graph transformer network
for reading a bank cheque is also described. It uses convolutional
neural network character recognizers combined with global training
techniques to provide record accuracy on business and personal cheques.
It is deployed commercially and reads several million cheques per day
},
author = {LeCun, Yann and Bottou, L\'{e}on and Bengio, Yoshua and Haffner, Patrick},
doi = {10.1109/5.726791},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/lecun-98.pdf:pdf},
isbn = {0018-9219},
issn = {00189219},
journal = {Proceedings of the IEEE},
keywords = {Convolutional neural networks,Document recognition,Finite state transducers,Gradient-based learning,Graph transformer networks,Machine learning,Neural networks,Optical character recognition (OCR)},
number = {11},
pages = {2278--2323},
pmid = {15823584},
title = {{Gradient-based learning applied to document recognition}},
volume = {86},
year = {1998}
}
@article{Lin2005,
abstract = {Data visualization techniques are very important for data analysis, since the human eye has been frequently advocated as the ultimate data-mining tool. However, there has been surprisingly little work on visualizing massive time series datasets. To this end, we developed VizTree, a time series pattern discovery and visualization system based on augmenting suffix trees. VizTree visually summarizes both the global and local structures of time series data at the same time. In addition, it provides novel interactive solutions to many pattern discovery problems, including the discovery of frequently occurring patterns (motif discovery), surprising patterns (anomaly detection), and query by content. VizTree works by transforming the time series into a symbolic representation, and encoding the data in a modified suffix tree in which the frequency and other properties of patterns are mapped onto colors and other visual properties. We demonstrate the utility of our system by comparing it with state-of- the-art batch algorithms on several real and synthetic datasets. Based on the tree structure, we further device a coefficient which measures the dissimilarity between any two time series. This coefficient is shown to be competitive with the well-known Euclidean distance.},
author = {Lin, Jessica and Keogh, Eamonn and Lonardi, Stefano},
doi = {10.1057/palgrave.ivs.9500089},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/SIGKDD\_2004\_vistree.pdf:pdf},
issn = {14738716},
journal = {Information Visualization},
number = {2},
pages = {61--82},
title = {{Visualizing and Discovering Non-Trivial Patterns In Large Time Series Databases}},
url = {http://dl.acm.org/citation.cfm?id=1103521},
volume = {4},
year = {2005}
}
@article{Lin2010,
author = {Lin, Zhen},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/3. August/Report/extra literatures/pcaVSvarimax.pdf:pdf},
number = {table 3},
pages = {1--5},
title = {{PCA vs. Varimax rotation}},
year = {2010}
}
@article{Maaten2008,
abstract = {We present a new technique called “t-SNE” that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images of objects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large data sets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence theway in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of data sets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualiza- tions produced by t-SNE are significantly better than those produced by the other techniques on almost all of the data sets.},
author = {Maaten, Laurens Van Der and Hinton, Geoffrey},
doi = {10.1007/s10479-011-0841-3},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/vandermaaten08a.pdf:pdf},
isbn = {1532-4435},
issn = {02545330},
journal = {Journal of Machine Learning Research},
keywords = {dimensionality reduction,embedding algorithms,manifold learning,multidimensional scaling,visualization},
pages = {2579--2605},
title = {{Visualizing Data using t-SNE}},
volume = {9},
year = {2008}
}
@article{Mahendran,
author = {Mahendran, Aravindh and Vedaldi, Andrea},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/mahendran15understanding.pdf:pdf},
title = {{Understanding Deep Image Representations by Inverting Them}}
}
@article{Marie2009,
author = {Marie, Tera and Card, Stuart and Mackinlay, Jock},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/Visualisation.pdf:pdf},
journal = {Ieee Computer Graphics And Applications},
pages = {0--3},
title = {{Visualization Viewpoints De ning Insight for Visual Analytics}},
year = {2009}
}
@misc{McCormick1987,
author = {McCormick, B H and DeFanti, T a and Brown, M D},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/McCormick-1987-VSC.pdf:pdf},
title = {{Visualization in Scientific Computing}},
url = {http://www.cogsci.ucsd.edu/~ajyu/Teaching/Cogs202\_sp13/Readings/hinton86.pdf},
year = {1987}
}
@article{Meihoefer1973,
author = {Meihoefer, Hans-Joachim},
doi = {10.3138/2771-5577-5417-369T},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/2771-5577-5417-369t.pdf:pdf},
isbn = {2771557754},
issn = {0317-7173},
journal = {Cartographica: The International Journal for Geographic Information and Geovisualization},
number = {1},
pages = {63--84},
title = {{the Visual Perception of the Circle in Thematic Maps/Experimental Results}},
volume = {10},
year = {1973}
}
@article{Meziane2004,
abstract = {Since their inception, entity relationship models have played a central role in systems speci�cation, analysis
and development. They have become an important part of several development methodologies and standards
such as SSADM. Obtaining entity relationship models, can however, be a lengthy and time consuming task for
all but the very smallest of speci�cations. This paper describes a semi-automatic approach for obtaining entity
relationship models from natural language speci�cations. The approach begins by using natural language
analysis techniques to translate sentences to a meaning representation language called logical form language.
The logical forms of the sentences are used as a basis for identifying the entities and relationships. Heuristics
are then used to suggest suitable degrees for the identi�ed relationships. This paper describes and illustrates
the main phases of the approach and presents a summary of the results obtained when it is applied to a case
study.},
author = {Meziane, F and Vadera, S},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Meziane, Vadera - 2004 - Obtaining E-R diagrams semi-automatically from natural language specifications.pdf:pdf},
isbn = {9728865007},
keywords = {Other,QA075 Electronic computers. Computer science},
pages = {638--642},
title = {{Obtaining E-R diagrams semi-automatically from natural language specifications}},
url = {http://usir.salford.ac.uk/1805/},
year = {2004}
}
@article{Mnih2013a,
abstract = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
archivePrefix = {arXiv},
arxivId = {1312.5602},
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
eprint = {1312.5602},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/1312.5602.pdf:pdf},
journal = {arXiv preprint arXiv: \ldots},
pages = {1--9},
title = {{Playing Atari with Deep Reinforcement Learning}},
url = {http://arxiv.org/abs/1312.5602},
year = {2013}
}
@article{Mnih2013,
abstract = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
archivePrefix = {arXiv},
arxivId = {1312.5602},
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
eprint = {1312.5602},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Mnih et al. - 2013 - Playing Atari with Deep Reinforcement Learning.pdf:pdf},
journal = {arXiv preprint arXiv: \ldots},
pages = {1--9},
title = {{Playing Atari with Deep Reinforcement Learning}},
url = {http://arxiv.org/abs/1312.5602},
year = {2013}
}
@article{Mnih2015,
abstract = {The theory of reinforcement learning provides a normative account 1 , deeply rooted in psychological 2 and neuroscientific 3 perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory pro-cessing systems 4,5 , the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopa-minergic neurons and temporal difference reinforcement learning algorithms 3 . While reinforcement learning agents have achieved some successes in a variety of domains 6–8 , their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks 9–11 to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games 12},
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei a and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
doi = {10.1038/nature14236},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/nature14236.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
number = {7540},
pages = {529--533},
publisher = {Nature Publishing Group},
title = {{Human-level control through deep reinforcement learning}},
url = {http://dx.doi.org/10.1038/nature14236},
volume = {518},
year = {2015}
}
@article{Mordvintsev2015,
author = {Mordvintsev, Alexander and Olah, Christopher and Tyka, Mike},
journal = {Google Research},
title = {{Inceptionism - going deeper into neural networks}},
url = {http://googleresearch.blogspot.co.uk/2015/06/inceptionism-going-deeper-into-neural.html},
year = {2015}
}
@article{Munro1992,
abstract = {For the visualizations, the backpropagation learning procedure was
applied to strictly layered feedforward networks with one hidden layer
that contained just two units. Values on the input units were binary (0,
1). The squashing function on the output units was the standard sigmoid
with upper and lower bounds at 0 and 1. An expanded range, (-1, 1) was
used for the hidden units to enhance learning speed and enhance the
separation of patterns in the HUAP visualization technique. The
resulting images reveal several properties of the hidden unit
representations achieved by backpropagation. These include (1) that the
normal solution to XOR collapses the pattern space to a one-dimensional
manifold and (2) the high symmetry of the hidden unit patterns achieved
in the <e1>N</e1>-2-<e1>N</e1> encoder task},
author = {Munro, P.W.},
doi = {10.1109/IJCNN.1992.227130},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/00227130.pdf:pdf},
isbn = {0-7803-0559-0},
journal = {[Proceedings 1992] IJCNN International Joint Conference on Neural Networks},
pages = {468--473},
title = {{Visualizations of 2-D hidden unit space}},
volume = {3},
year = {1992}
}
@book{Murray2013,
abstract = {Create and publish your own interactive data visualization projects on the Web—even if you have little or no experience with data visualization or web development. It’s easy and fun with this practical, hands-on introduction. Author Scott Murray teaches you the fundamental concepts and methods of D3, a JavaScript library that lets you express data visually in a web browser. Along the way, you’ll expand your web programming skills, using tools such as HTML and JavaScript. This step-by-step guide is ideal whether you’re a designer or visual artist with no programming experience, a reporter exploring the new frontier of data journalism, or anyone who wants to visualize and share data. Learn HTML, CSS, JavaScript, and SVG basics Dynamically generate web page elements from your data—and choose visual encoding rules to style them Create bar charts, scatter plots, pie charts, stacked bar charts, and force-directed layouts Use smooth, animated transitions to show changes in your data Introduce interactivity to help users explore data through different views Create customized geographic maps with data Explore hands-on with downloadable code and over 100 examples},
author = {Murray, Scott},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/Interactive Data Visualization For The Web.pdf:pdf},
isbn = {1449339735},
pages = {272},
title = {{Interactive Data Visualization for the Web}},
url = {http://www.amazon.com/Interactive-Data-Visualization-Scott-Murray/dp/1449339735},
year = {2013}
}
@article{Ng2007,
abstract = {Sensible review of the enormous problems of head injuries noting that they are a major cause of morbidity and mortality, that they are commonest in the younger age groups, that they are associated with major psychological components of damage including immense knock-on effects on families and carers. Notes that the services are unfunded. Refs.},
author = {Ng, Andrew},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Ng - 2007 - Advice for applying Machine Learning.pdf:pdf},
journal = {I Can},
pages = {141--146},
title = {{Advice for applying Machine Learning}},
volume = {153},
year = {2007}
}
@article{Ng2013,
author = {Ng, Andrew},
journal = {Coursera},
title = {{Machine Learning}},
year = {2013}
}
@article{Nguyen2015,
abstract = {Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between com- puter and human vision. A recent study [30] revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the- art DNNs believe to be recognizable objects with 99.99\% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neu- ral networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possi- ble to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call “fooling images” (more generally, fooling ex- amples). Our results shed light on interesting differences between human vision and current DNNs, and raise ques- tions about the generality of DNN computer vision},
archivePrefix = {arXiv},
arxivId = {arXiv:1412.1897v4},
author = {Nguyen, a and Yosinski, J and Clune, J},
eprint = {arXiv:1412.1897v4},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/1412.1897v4.pdf:pdf},
journal = {Cvpr 2015},
title = {{Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images}},
url = {http://arxiv.org/abs/1412.1897},
year = {2015}
}
@article{Nielsen2014,
author = {Nielsen, Michael},
title = {{Neural Networks and Deep Learning}},
url = {http://neuralnetworksanddeeplearning.com/},
year = {2014}
}
@article{Norouzi2014,
abstract = {Several recent publications have proposed methods for mapping images into con- tinuous semantic embedding spaces. In some cases the embedding space is trained jointly with the image transformation. In other cases the semantic embedding space is established by an independent natural language processing task, and then the image transformation into that space is learned in a second stage. Proponents of these image embedding systems have stressed their advantages over the traditional n-way classification framing of image understanding, particularly in terms of the promise for zero-shot learning – the ability to correctly annotate images of previously unseen object categories. In this paper, we propose a simple method for constructing an image embedding system from any existing n-way image classifier and a semantic word embedding model, which contains the n class labels in its vocabulary. Our method maps images into the semantic embedding space via convex combination of the class label embedding vectors, and requires no addi- tional training. We show that this simple and direct method confers many of the advantages associated with more complex image embedding schemes, and indeed outperforms state of the art methods on the ImageNet zero-shot learning task.},
archivePrefix = {arXiv},
arxivId = {arXiv:1312.5650v3},
author = {Norouzi, Mohammad and Mikolov, Tomas and Bengio, Samy and Singer, Yoram and Mar, L G},
eprint = {arXiv:1312.5650v3},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/1312.5650.pdf:pdf},
journal = {ArXiV},
keywords = {0-shot learning by convex,combination of},
pages = {1--9},
title = {{Zero-Shot Learning by Convex Combination of Semantic Embeddings}},
year = {2014}
}
@article{North,
author = {North, Chris},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/Visualising Multi Dimensional Data.pdf:pdf},
title = {{Multi-Dimensional Data Visualization}}
}
@misc{Olah2014b,
author = {Olah, Chris},
booktitle = {Colah's Blog},
title = {{Visualizing MNIST: An Exploration of Dimensionality Reduction}},
url = {http://colah.github.io/posts/2014-10-Visualizing-MNIST/},
urldate = {2015-06-08},
year = {2014}
}
@misc{Olah2014a,
author = {Olah, Chris},
booktitle = {Colah's Blog},
title = {{Neural Networks, Manifolds, and Topology}},
url = {http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/},
urldate = {2015-06-08},
year = {2014}
}
@misc{Olah2014,
author = {Olah, Chris},
booktitle = {Colah's Blog},
title = {{Visualizing Representations: Deep Learning and Human Beings}},
url = {http://colah.github.io/posts/2015-01-Visualizing-Representations/\#fn10},
urldate = {2015-06-08},
year = {2014}
}
@article{Olah2014c,
author = {Olah, Christopher},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/Deep Learning, NLP, and Representations - colah's blog.pdf:pdf},
pages = {1--9},
title = {{Deep Learning , NLP , and Representations}},
year = {2014}
}
@article{Patel2008,
author = {Patel, Kayur and Fogarty, James and Landay, James a and Harrison, Beverly},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/aaai2008-learningtools.pdf:pdf},
isbn = {9781577353683},
journal = {Proc. AAAI 2008},
number = {Hand 1998},
pages = {1998--2001},
title = {{Examining Difficulties Software Developers Encounter in the Adoption of Statistical Machine Learning}},
year = {2008}
}
@article{Pearson2013,
author = {Pearson, Paul T.},
doi = {10.1155/2013/486363},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/486363.pdf:pdf},
issn = {1687-7594},
journal = {Advances in Artificial Neural Systems},
pages = {1--8},
title = {{Visualizing Clusters in Artificial Neural Networks Using Morse Theory}},
url = {http://www.hindawi.com/journals/aans/2013/486363/},
volume = {2013},
year = {2013}
}
@article{Pieters2012,
author = {Pieters, Roelof},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/2014-10-21sicsdlnlpg-141022031857-conversion-gate02.pdf:pdf},
title = {{Deep Learning and NPL: Grapjs}},
year = {2012}
}
@article{Rajaraman2011,
abstract = {At the highest level of description, this book is about data mining. However, it focuses on data mining of very large amounts of data, that is, data so large it does not fit in main memory. Because of the emphasis on size, many of our examples are about the Web or data derived from the Web. Further, the book takes an algorithmic point of view: data mining is about applying algorithms to data, rather than using data to train a machine-learning engine of some sort.},
author = {Rajaraman, Anand and Ullman, Jeffrey D},
doi = {10.1017/CBO9781139058452},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Rajaraman, Ullman - 2011 - Mining of Massive Datasets.pdf:pdf},
isbn = {9781139058452},
issn = {01420615},
journal = {Lecture Notes for Stanford CS345A Web Mining},
pages = {328},
title = {{Mining of Massive Datasets}},
url = {http://ebooks.cambridge.org/ref/id/CBO9781139058452},
volume = {67},
year = {2011}
}
@article{Rajdev,
author = {Rajdev, Jesal and Rajdev, Jesal},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Rajdev, Rajdev - Unknown - Library Visualisation and Interaction Display.pdf:pdf},
title = {{Library Visualisation and Interaction Display}}
}
@article{Ree2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1412.6564v1},
author = {Ree, T},
eprint = {arXiv:1412.6564v1},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/deepgo.pdf:pdf},
number = {3},
pages = {1--23},
title = {{P2P Domain C Lassification U Sing D Ecision}},
volume = {2},
year = {2011}
}
@article{Rezende2014,
abstract = {Abstract We marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep , directed generative models , endowed with a new algorithm for scalable inference and learning. Our algorithm introduces a recognition ... $\backslash$n},
archivePrefix = {arXiv},
arxivId = {arXiv:1401.4082v3},
author = {Rezende, D J and Mohamed, S and Wierstra, D},
eprint = {arXiv:1401.4082v3},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/1401.4082v3.pdf:pdf},
isbn = {9781634393973},
journal = {Proceedings of The 31st \ldots},
keywords = {ICML2014},
title = {{Stochastic backpropagation and approximate inference in deep generative models}},
url = {http://jmlr.org/proceedings/papers/v32/rezende14.html$\backslash$npapers3://publication/uuid/F2747569-7719-4EAC-A5A7-9ECA9D6A8FE6},
year = {2014}
}
@article{Rieser2011,
author = {Rieser, Verena and Robinson, Derek T and Murray-rust, Dave and Rounsevell, Mark},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Rieser et al. - 2011 - A Comparison of Genetic Algorithms and Reinforcement Learning for Optimising Sustainable Forest Management.pdf:pdf},
pages = {20--24},
title = {{A Comparison of Genetic Algorithms and Reinforcement Learning for Optimising Sustainable Forest Management}},
year = {2011}
}
@article{Romero2011,
abstract = {The ever-increasing amount of information flowing through Social Media forces the members of these networks to compete for attention and influence by relying on other people to spread their message. A large study of information propagation within Twitter reveals that the majority of users act as passive information consumers and do not forward the content to the network. Therefore, in order for individuals to become influential they must not only obtain attention and thus be popular, but also overcome user passivity. We propose an algorithm that determines the influence and passivity of users based on their information forwarding activity. An evaluation performed with a 2.5 million user dataset shows that our influence measure is a good predictor of URL clicks, outperforming several other measures that do not explicitly take user passivity into account. We also explicitly demonstrate that high popularity does not necessarily imply high influence and vice-versa.},
archivePrefix = {arXiv},
arxivId = {1008.1253},
author = {Romero, Daniel M. and Galuba, Wojciech and Asur, Sitaram and Huberman, Bernardo a.},
doi = {10.1007/978-3-642-23808-6\_2},
eprint = {1008.1253},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Romero et al. - 2011 - Influence and passivity in social media.pdf:pdf},
isbn = {9783642238079},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {PART 3},
pages = {18--33},
title = {{Influence and passivity in social media}},
volume = {6913 LNAI},
year = {2011}
}
@article{Roux2008,
abstract = {Guided by the goal of obtaining an optimization algorithm that is both fast and yielding good generalization, we study the descent direction maximizing the decrease in generalization error or the probability of not increasing generalization error. The surprising result is that from both the Bayesian and frequentist perspectives this can yield the natural gradient direction. Although that direction can be very expensive to compute we develop an efficient, general, online approximation to the natural gradient descent which is suited to large scale problems. We report experimental results showing much faster convergence in computation time and in number of iterations with TONGA (Topmoumoute Online natural Gradient Algorithm) than with stochastic gradient descent, even on very large datasets.},
author = {Roux, Nicolas Le and Manzagol, Pierre-Antoine and Bengio, Yoshua},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/10.1.1.188.692.pdf:pdf},
isbn = {160560352X},
journal = {Advances in Neural Information Processing Systems 20},
number = {1299},
pages = {1--8},
title = {{Topmoumoute online natural gradient algorithm}},
year = {2008}
}
@article{Roweis2000,
abstract = {Many areas of science depend on exploratory data analysis and visualization. The need to analyze large amounts of multivariate data raises the fundamental problem of dimensionality reduction: how to discover compact representations of high-dimensional data. Here, we introduce locally linear embedding (LLE), an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs. Unlike clustering methods for local dimensionality reduction, LLE maps its inputs into a single global coordinate system of lower dimensionality, and its optimizations do not involve local minima. By exploiting the local symmetries of linear reconstructions, LLE is able to learn the global structure of nonlinear manifolds, such as those generated by images of faces or documents of text.},
author = {Roweis, S T and Saul, L K},
doi = {10.1126/science.290.5500.2323},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/roweis.pdf:pdf},
isbn = {00368075},
issn = {0036-8075},
journal = {Science (New York, N.Y.)},
number = {5500},
pages = {2323--2326},
pmid = {11125150},
title = {{Nonlinear dimensionality reduction by locally linear embedding.}},
volume = {290},
year = {2000}
}
@article{Russakovsky2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1409.0575v3},
author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Jan, C. V. and Krause, J. and Ma, S.},
eprint = {arXiv:1409.0575v3},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/1409.0575.pdf:pdf},
journal = {arXiv preprint arXiv:1409.0575},
keywords = {benchmark,dataset,large-scale,object detection,object recognition},
title = {{ImageNet Large Scale Visual Recognition Challenge}},
year = {2015}
}
@article{Sainath2015,
author = {Sainath, Tara N. and Kingsbury, Brian and Saon, George and Soltau, Hagen and Mohamed, Abdel-rahman and Dahl, George and Ramabhadran, Bhuvana},
doi = {10.1016/j.neunet.2014.08.005},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/1-s2.0-S0893608014002007-main.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
pages = {39--48},
publisher = {Elsevier Ltd},
title = {{Deep Convolutional Neural Networks for Large-scale Speech Tasks}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0893608014002007},
volume = {64},
year = {2015}
}
@article{Sammon1969,
address = {Washington, DC, USA},
author = {Sammon, J W},
doi = {10.1109/T-C.1969.222678},
issn = {0018-9340},
journal = {IEEE Trans. Comput.},
keywords = {Clustering,dimensionality reduction,mappings,multidimensional scaling,multivariate data analysis,nonparametric,pattern recognition,statistics.},
month = may,
number = {5},
pages = {401--409},
publisher = {IEEE Computer Society},
title = {{A Nonlinear Mapping for Data Structure Analysis}},
url = {http://dx.doi.org/10.1109/T-C.1969.222678},
volume = {18},
year = {1969}
}
@article{Satyanarayan2012,
abstract = {The Web is an enormous and diverse repository of design examples. Although people often draw from extant designs to create new ones, existing Web design tools do not facilitate example reuse in a way that captures the scale and diversity of the Web. To do so requires using machine learning techniques to train computational models which can be queried during the design process. In this work-in-progress, we present a platform necessary for doing such large-scale machine learning on Web designs, which consists of a Web crawler and proxy server to harvest and store a lossless and immutable snapshot of the Web; a page segmenter that codifies a page's visual layout; and an interface for augmenting the segmentations with crowdsourced metadata.},
author = {Satyanarayan, Arvind and Lim, Maxine and Klemmer, Scott},
doi = {10.1145/2212776.2223695},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Satyanarayan, Lim, Klemmer - 2012 - A platform for large-scale machine learning on web design.pdf:pdf},
isbn = {9781450310161},
journal = {Proceedings of the 2012 ACM annual conference extended abstracts on Human Factors in Computing Systems Extended Abstracts - CHI EA '12},
pages = {1697--1702},
title = {{A platform for large-scale machine learning on web design}},
url = {http://dl.acm.org/citation.cfm?id=2223695$\backslash$nhttp://dl.acm.org/citation.cfm?doid=2212776.2223695},
year = {2012}
}
@article{Schacter2012,
abstract = {During the past few years, there has been a dramatic increase in research examining the role of memory in imagination and future thinking. This work has revealed striking similarities between remembering the past and imagining or simulating the future, including the finding that a common brain network underlies both memory and imagination. Here, we discuss a number of key points that have emerged during recent years, focusing in particular on the importance of distinguishing between temporal and nontemporal factors in analyses of memory and imagination, the nature of differences between remembering the past and imagining the future, the identification of component processes that comprise the default network supporting memory-based simulations, and the finding that this network can couple flexibly with other networks to support complex goal-directed simulations. This growing area of research has broadened our conception of memory by highlighting the many ways in which memory supports adaptive functioning.},
author = {Schacter, Daniel L. and Addis, Donna Rose and Hassabis, Demis and Martin, Victoria C. and Spreng, R. Nathan and Szpunar, Karl K.},
doi = {10.1016/j.neuron.2012.11.001},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/FutureMemory--Neuron12.pdf:pdf},
isbn = {1097-4199 (Electronic)$\backslash$n0896-6273 (Linking)},
issn = {08966273},
journal = {Neuron},
number = {4},
pages = {677--694},
pmid = {23177955},
title = {{The Future of Memory: Remembering, Imagining, and the Brain}},
volume = {76},
year = {2012}
}
@article{Schaul2013,
abstract = {The performance of stochastic gradient descent (SGD) depends critically on how learning rates are tuned and decreased over time. We propose a method toautomatically adjust multiple learning rates so as to minimize the expected error at any one time. The method relies on local gradient variations across samples. In our approach, learning rates can increase as well as decrease, making it suitable for non-stationary problems. Using a number of convex and non-convex learning tasks, we show that the resulting algorithm matches the performance of the best settings obtained through systematic search, and effectively removes the need for learning rate tuning.},
archivePrefix = {arXiv},
arxivId = {arXiv:1206.1106v2},
author = {Schaul, Tom and Zhang, Sixin and LeCun, Yann},
eprint = {arXiv:1206.1106v2},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/1206.1106.pdf:pdf},
journal = {Journal of Machine Learning Research},
number = {2},
pages = {343--351},
title = {{No More Pesky Learning Rates}},
volume = {28},
year = {2013}
}
@article{Scheiter2010,
abstract = {In this paper the augmentation of worked examples with animations for teaching problem-solving skills in mathematics is advocated as an effective instructional method. First, in a cognitive task analysis different knowledge prerequisites are identified for solving mathematical word problems. Second, it is argued that so called hybrid animations would be most effective for acquiring these prerequisites, because they show the continuous transition from a concrete, but superficial problem representation to a more abstract, mathematical problem model that forms a basis for solving a problem. An experiment was conducted, where N = 32 pupils from a German high school studied either only text-based worked examples explaining different problem categories from the domain of algebra or worked examples augmented with hybrid animations. Learners with hybrid animations showed superior problem-solving performance for problems of different transfer distance relative to those in the text-only condition.},
author = {Scheiter, Katharina and Gerjets, Peter and Schuh, Julia},
doi = {10.1007/s11251-009-9114-9},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/art\%3A10.1007\%2Fs11251-009-9114-9.pdf:pdf},
isbn = {0020-4277},
issn = {00204277},
journal = {Instructional Science},
keywords = {Animation,Dynamic visualization,Problem solving,Skill acquisition in mathematics,Worked examples},
number = {5},
pages = {487--502},
title = {{The acquisition of problem-solving skills in mathematics: How animations can aid understanding of structural problem features and solution procedures}},
volume = {38},
year = {2010}
}
@article{Schmidh\uber2014,
abstract = {In recent years, deep neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarises relevant work, much of it from the previous millennium. Shallow and deep learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \& evolutionary computation, and indirect search for short programs encoding deep and large networks.},
archivePrefix = {arXiv},
arxivId = {1404.7828},
author = {Schmidh\{$\backslash$"u\}ber, Juergen},
doi = {10.1016/j.neunet.2014.09.003},
eprint = {1404.7828},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/1404.7828v4.pdf:pdf},
issn = {18792782},
journal = {arXiv preprint arXiv: \ldots},
pages = {66},
title = {{Deep Learning in Neural Networks: An Overview}},
url = {http://arxiv.org/abs/1404.7828},
volume = {abs/1404.7},
year = {2014}
}
@article{Scientists2013,
author = {Scientists, Computer and Harvard, a T and Scientists, Cognitive and Mit, a T and Up, Team and Settle, T O},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/Borkin\_etal\_MemorableVisualization\_TVCG2013.pdf:pdf},
number = {617},
pages = {1--6},
title = {{What makes a data visualization memorable ?}},
year = {2013}
}
@article{Selassie2011,
abstract = {The node-link diagram is an intuitive and venerable way to depict a graph. To reduce clutter and improve the readability of node-link views, Holten \&amp; van Wijk's force-directed edge bundling employs a physical simulation to spatially group graph edges. While both useful and aesthetic, this technique has shortcomings: it bundles spatially proximal edges regardless of direction, weight, or graph connectivity. As a result, high-level directional edge patterns are obscured. We present divided edge bundling to tackle these shortcomings. By modifying the forces in the physical simulation, directional lanes appear as an emergent property of edge direction. By considering graph topology, we only bundle edges related by graph structure. Finally, we aggregate edge weights in bundles to enable more accurate visualization of total bundle weights. We compare visualizations created using our technique to standard force-directed edge bundling, matrix diagrams, and clustered graphs; we find that divided edge bundling leads to visualizations that are easier to interpret and reveal both familiar and previously obscured patterns.},
author = {Selassie, David and Heller, Brandon and Heer, Jeffrey},
doi = {10.1109/TVCG.2011.190},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/2011-DividedEdgeBundling-InfoVis.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Graph visualization,aggregation,edge bundling,node-link diagrams,physical simulation},
number = {12},
pages = {2354--2363},
pmid = {22034356},
title = {{Divided edge bundling for directional network data}},
volume = {17},
year = {2011}
}
@article{Sha2010,
author = {Sha, Fei},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/tutorialPart1.pdf:pdf},
title = {{Machine Learning for Information Visualization Part II}},
year = {2010}
}
@article{Shoresh2011,
abstract = {Enhancement of pattern discovery through graphical representation of data.},
author = {Shoresh, Noam and Wong, Bang},
doi = {10.1038/nmeth.1829},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/nmeth.1829.pdf:pdf},
isbn = {1548-7105 (Electronic)$\backslash$n1548-7091 (Linking)},
issn = {1548-7091},
journal = {Nature Methods},
number = {1},
pages = {5--5},
pmid = {22312636},
publisher = {Nature Publishing Group},
title = {{Points of view: Data exploration}},
url = {http://dx.doi.org/10.1038/nmeth.1829},
volume = {9},
year = {2011}
}
@article{Simard2003,
abstract = {Not Available},
author = {Simard, P Y and Steinkraus, D and Platt, John C},
doi = {10.1109/ICDAR.2003.1227801},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/icdar03.pdf:pdf},
isbn = {0-7695-1960-1},
journal = {Document Analysis and Recognition, 2003. Proceedings. Seventh International Conference on},
keywords = {Best practices,Concrete,Convolution,Handwriting recognition,Industrial training,Information processing,Neural networks,Performance analysis,Support vector machines,Text analysis},
pages = {958--963},
title = {{Best practices for convolutional neural networks applied to visual document analysis}},
year = {2003}
}
@article{Simard2003a,
abstract = {Neural networks are a powerful technology for classification of visual inputs arising from documents. However, there is a confusing plethora of different neural network methods that are used in the literature and in industry. This paper describes a set of concrete best practices that document analysis researchers can use to get good results with neural networks. The most important practice is getting a training set as large as possible: we expand the training set by adding a new form of distorted data. The next most important practice is that convolutional neural networks are better suited for visual document tasks than fully connected networks. We propose that a simple "do-it-yourself" implementation of convolution with a flexible architecture is suitable for many visual document problems. This simple convolutional neural network does not require complex methods, such as momentum, weight decay, structure-dependent learning rates, averaging layers, tangent prop, or even finely-tuning the architecture. The end result is a very simple yet general architecture which can yield state-of-the-art performance for document analysis. We illustrate our claims on the MNIST set of English digit images.},
author = {Simard, P.Y. and Steinkraus, D. and Platt, J.C.},
doi = {10.1109/ICDAR.2003.1227801},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/First 39 Images.pdf:pdf},
isbn = {0-7695-1960-1},
journal = {Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.},
pages = {24--25},
title = {{Best practices for convolutional neural networks applied to visual document analysis}},
year = {2003}
}
@article{Simonyan2013,
abstract = {This paper addresses the visualisation of image classification models, learnt using deep Convolutional Networks (ConvNets). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The first one generates an image, which maximises the class score [Erhan et al., 2009], thus visualising the notion of the class, captured by a ConvNet. The second technique computes a class saliency map, specific to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classification ConvNets. Finally, we establish the connection between the gradient-based ConvNet visualisation methods and deconvolutional networks [Zeiler et al., 2013].},
archivePrefix = {arXiv},
arxivId = {1312.6034},
author = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
eprint = {1312.6034},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/1312.6034v2.pdf:pdf},
journal = {arXiv preprint arXiv:1312.6034},
pages = {1--8},
title = {{Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps}},
url = {http://arxiv.org/abs/1312.6034},
year = {2013}
}
@article{Song2007,
abstract = {Maximum variance unfolding (MVU) is an effective heuristic for dimensionality
reduction. It produces a low-dimensional representation of the data by maximizing
the variance of their embeddings while preserving the local distances of the
original data. We show that MVU also optimizes a statistical dependence measure
which aims to retain the identity of individual observations under the distancepreserving
constraints. This general view allows us to design “colored” variants
of MVU, which produce low-dimensional representations for a given task, e.g.
subject to class labels or other side information.},
author = {Song, Le and Smola, Alex and Borgwardt, Karsten and Gretton, Arthur},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/3307-colored-maximum-variance-unfolding.pdf:pdf},
isbn = {978-1-605-60352-0},
keywords = {Computational, Information-Theoretic Learning with,Theory \& Algorithms},
pages = {1--8},
title = {{Colored Maximum Variance Unfolding}},
url = {http://eprints.pascal-network.org/archive/00003144/},
year = {2007}
}
@article{Stefaner2007,
abstract = {Master's Thesis},
author = {Stefaner, Moritz},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/thesis\_stefaner\_screen.pdf:pdf},
journal = {Thesis},
number = {June},
pages = {1--112},
title = {{Visual Tools for the Socio-Semantic Web}},
url = {papers3://publication/uuid/8C9E950C-75C5-4A3A-9E69-0A4154B46F67},
year = {2007}
}
@article{Stolte2002,
abstract = {In the last several years, large multidimensional databases have$\backslash$nbecome common in a variety of applications, such as data warehousing and$\backslash$nscientific computing. Analysis and exploration tasks place significant$\backslash$ndemands on the interfaces to these databases. Because of the size of the$\backslash$ndata sets, dense graphical representations are more effective for$\backslash$nexploration than spreadsheets and charts. Furthermore, because of the$\backslash$nexploratory nature of the analysis, it must be possible for the analysts$\backslash$nto change visualizations rapidly as they pursue a cycle involving first$\backslash$nhypothesis and then experimentation. In this paper, we present Polaris,$\backslash$nan interface for exploring large multidimensional databases that extends$\backslash$nthe well-known pivot table interface. The novel features of Polaris$\backslash$ninclude an interface for constructing visual specifications of$\backslash$ntable-based graphical displays and the ability to generate a precise set$\backslash$nof relational queries from the visual specifications. The visual$\backslash$nspecifications can be rapidly and incrementally developed, giving the$\backslash$nanalyst visual feedback as he constructs complex queries and$\backslash$nvisualizations},
author = {Stolte, C. and Tang, D. and Hanrahan, P.},
doi = {10.1109/2945.981851},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/polaris.pdf:pdf},
isbn = {158113567X},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {1},
pages = {1--14},
title = {{Polaris: a system for query, analysis, and visualization of$\backslash$nmultidimensional relational databases}},
volume = {8},
year = {2002}
}
@article{Streeter2001,
author = {Streeter, Matthew and Ward, Matthew and Alvarez, Sergio a},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/mstreeter\_spie\_2001.pdf:pdf},
keywords = {evolutionary computation,graphs,neural networks,visualization},
title = {{NVIS : an interactive visualization tool for neural networks}},
year = {2001}
}
@article{Sundsøy2014,
author = {Sunds\o y, P\aa l and Bjelland, Johannes and Iqbal, Asif M. and Pentland, Alex and {De Montjoye}, Yves Alexandre},
doi = {10.1007/978-3-319-05579-4-45},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Sunds\o y et al. - 2014 - Big data-driven marketing How machine learning outperforms marketers' gut-feeling.pdf:pdf},
isbn = {9783319055787},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Asia,Big Data,Carrier,Machine learning,Marketing,Metadata,Mobile Network Operator,social network analysis},
pages = {367--374},
title = {{Big data-driven marketing: How machine learning outperforms marketers' gut-feeling}},
volume = {8393 LNCS},
year = {2014}
}
@article{Sung1998,
abstract = {Artificial neural networks have been used for simulation, modeling, and control purposes in many engineering applications as an alternative to conventional expert systems. Although neural networks usually do not reach the level of performance exhibited by expert systems, they do enjoy a tremendous advantage of very low construction costs. This paper addresses the issue of identifying important input parameters in building a multilayer, backpropagation network for a typical class of engineering problems. These problems are characterized by having a large number of input variables of varying degrees of importance; and identifying the important variables is a common issue since elimination of the unimportant inputs leads to a simplification of the problem and often a more accurate modeling or solution. We compare three different methods for ranking input importance: sensitivity analysis, fuzzy curves, and change of MSE (mean square error); and analyze their effectiveness. Simulation results based on experiments with simple mathematical functions as well as a real engineering problem are reported. Based on the analysis and our experience in building neural networks, we also propose a general methodology for building backpropagation networks for typical engineering applications.},
author = {Sung, A},
doi = {10.1016/S0957-4174(98)00041-4},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/1-s2.0-S0957417498000414-main.pdf:pdf},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {artificial neural networks,change of mse,fuzzy curves,importance ranking,sensitivity analysis},
number = {3-4},
pages = {405--411},
title = {{Ranking importance of input parameters of neural networks}},
volume = {15},
year = {1998}
}
@article{Sussillo2013,
abstract = {Recurrent neural networks (RNNs) are useful tools for learning nonlinear relationships between time-varying inputs and outputs with complex temporal dependencies. Recently developed algorithms have been successful at training RNNs to perform a wide variety of tasks, but the resulting networks have been treated as black boxes: their mechanism of operation remains unknown. Here we explore the hypothesis that fixed points, both stable and unstable, and the linearized dynamics around them, can reveal crucial aspects of how RNNs implement their computations. Further, we explore the utility of linearization in areas of phase space that are not true fixed points but merely points of very slow movement. We present a simple optimization technique that is applied to trained RNNs to find the fixed and slow points of their dynamics. Linearization around these slow regions can be used to explore, or reverse-engineer, the behavior of the RNN. We describe the technique, illustrate it using simple examples, and finally showcase it on three high-dimensional RNN examples: a 3-bit flip-flop device, an input-dependent sine wave generator, and a two-point moving average. In all cases, the mechanisms of trained networks could be inferred from the sets of fixed and slow points and the linearized dynamics around them.},
author = {Sussillo, David and Barak, Omri},
doi = {10.1162/NECO\_a\_00409},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/sussillo\_barak-neco.pdf:pdf},
isbn = {10.1162/NECO\_a\_00409},
issn = {1530-888X},
journal = {Neural computation},
keywords = {Artificial Intelligence,Neural Networks (Computer)},
number = {3},
pages = {626--49},
pmid = {23272922},
title = {{Opening the black box: low-dimensional dynamics in high-dimensional recurrent neural networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23272922},
volume = {25},
year = {2013}
}
@article{Sutskever2013,
abstract = {Deep and recurrent neural networks (DNNs and RNNs respectively) are powerful models that were considered to be almost impossible to train using stochastic gradient descent with momentum. In this paper, we show that when stochastic gradient descent with momentum uses a well-designed random initialization and a particular type of slowly increasing schedule for the momentum parameter, it can train both DNNs and RNNs (on datasets with long-term dependencies) to levels of performance that were previously achievable only with Hessian-Free optimization. We find that both the initialization and the momentum are crucial since poorly initialized networks cannot be trained with momentum and well-initialized networks perform markedly worse when the momentum is absent or poorly tuned. Our success training these models suggests that previous attempts to train deep and recurrent neural networks from random initializations have likely failed due to poor initialization schemes. Furthermore, carefully tuned momentum methods suffice for dealing with the curvature issues in deep and recurrent network training objectives without the need for sophisticated second-order methods.},
author = {Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
doi = {10.1109/ICASSP.2013.6639346},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/sutskever13.pdf:pdf},
isbn = {978-1-4799-0356-6},
journal = {Jmlr W\&Cp},
number = {2010},
pages = {1139--1147},
title = {{On the importance of initialization and momentum in deep learning}},
volume = {28},
year = {2013}
}
@article{Sutskever2014,
archivePrefix = {arXiv},
arxivId = {1409.3215},
author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
eprint = {1409.3215},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/1409.3215v3.pdf:pdf},
journal = {Nips 2014},
pages = {1--9},
title = {{Sequence to Sequence Learning with Neural Networks}},
year = {2014}
}
@article{Szegedy2014,
archivePrefix = {arXiv},
arxivId = {1409.4842v1},
author = {Szegedy, Christian and Reed, Scott and Sermanet, Pierre and Vanhoucke, Vincent and Rabinovich, Andrew},
eprint = {1409.4842v1},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/1409.4842.pdf:pdf},
pages = {1--12},
title = {{Going deeper with convolutions}},
year = {2014}
}
@article{Talbot2009,
abstract = {Machine learning is an increasingly used computational tool within human-computer interaction research. While most researchers currently utilize an iterative approach to refining classifier models and performance, we propose that ensemble classification techniques may be a viable and even preferable alternative. In ensemble learning, algorithms combine multiple classifiers to build one that is superior to its components. In this paper, we present EnsembleMatrix, an interactive visualization system that presents a graphical view of confusion matrices to help users understand relative merits of various classifiers. EnsembleMatrix allows users to directly interact with the visualizations in order to explore and build combination models. We evaluate the efficacy of the system and the approach in a user study. Results show that users are able to quickly combine multiple classifiers operating on multiple feature sets to produce an ensemble classifier with accuracy that approaches best-reported performance classifying images in the CalTech-101 dataset.},
author = {Talbot, Justin and Lee, Bongshin and Kapoor, Ashish and Tan, Desney S},
doi = {10.1145/1518701.1518895},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/2009-EnsembleMatrix-CHI.pdf:pdf},
isbn = {9781605582467},
journal = {Learning},
pages = {1283--1292},
title = {{EnsembleMatrix: interactive visualization to support machine learning with multiple classifiers}},
url = {http://portal.acm.org/citation.cfm?id=1518895},
year = {2009}
}
@book{Teller2013,
author = {Teller, S},
booktitle = {Zhurnal Eksperimental'noi i Teoreticheskoi Fiziki},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/Data Visualization with D3.js Cookbook.pdf:pdf},
isbn = {9781782160007},
title = {{Data Visualization with D3. js}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:No+Title\#0$\backslash$nhttp://books.google.com/books?hl=en\&lr=\&id=1Qm8AQAAQBAJ\&oi=fnd\&pg=PT6\&dq=Data+Visualization+with+d3.js+Mold\&ots=Zg0OGMlMT\_\&sig=WhiMVY9Wrlb7izx9RAVplWy41I8},
year = {2013}
}
@article{Tenenbaum2000,
author = {Tenenbaum, Joshua B and Silva, Vin De and Langford, John C},
doi = {10.1126/science.290.5500.2319},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/isomap.pdf:pdf},
issn = {0036-8075},
number = {December},
pages = {2319--2323},
pmid = {11125149},
title = {{Sci\_Reprint}},
volume = {290},
year = {2000}
}
@article{Torgerson1952,
author = {Torgerson, Warren S},
title = {{Multidimensional scaling: I. Theory and method}},
year = {1952}
}
@misc{Tufle1983,
abstract = {Tufte, E. R., \& Graves-Morris, P. R. (1983). The visual display of quantitative information (Vol. 2). Cheshire, CT: Graphics press.},
author = {Tufle, Er},
booktitle = {CT Graphics, Cheshire},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/TufteCoversheet.pdf:pdf},
isbn = {978-0961392147},
title = {{The visual display of quantitative information}},
url = {http://www.colorado.edu/UCB/AcademicAffairs/ArtsSciences/geography/foote/maps/assign/reading/TufteCoversheet.pdf},
year = {1983}
}
@article{Tufte2010,
author = {Tufte, Edward},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/IDMG-SummerSeries-06-01-2010-TufteInTwentyMinutes.pdf:pdf},
journal = {Analysis},
title = {{Presentation Boot Camp ( aka Tufte in Twenty Minutes )}},
volume = {1812},
year = {2010}
}
@book{Tufte2001,
address = {Cheshire, Conn.},
annote = {Includes index.},
author = {Tufte, Edward R},
edition = {2nd ed.},
isbn = {ISBN: 0961392142},
keywords = {Statistics -- Graphic methods.},
publisher = {Graphics Press},
title = {{The visual display of quantitative information}},
year = {2001}
}
@article{Tufte2012,
author = {Tufte, Edward and Sigma, Mu},
title = {{Why Visualisation}},
url = {http://www.mu-sigma.com/uvnewsletter/index.html},
year = {2012}
}
@article{Tzeng2005,
abstract = {Arti cial neural networks are computer software or hardware models inspired by the structure and behavior of neurons in the human nervous system. As a powerful learning tool, increasingly neural networks have been adopted by many large-scale information processing applications but there is no a set of well de ned criteria for choosing a neural network. The user mostly treats a neural network as a black box and cannot explain how learning from input data was done nor how performance can be consistently ensured. We have experimented with several information visualization designs aiming to open the black box to possibly uncover underlying dependencies between the input data and the output data of a neural network. In this paper, we present our designs and show that the visualizations not only help us design more ef cient neural networks, but also assist us in the process of using neural networks for problem solving such as performing a classi cation task.},
author = {Tzeng, Fan-Yin and Ma, Kwan-Liu},
doi = {10.1109/VISUAL.2005.1532820},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/Vis05\_Tzeng.pdf:pdf},
isbn = {0-7803-9462-3},
journal = {VIS 05. IEEE Visualization, 2005.},
keywords = {arti cial neural network,classi cation,information visualization,machine learning,visualization application},
number = {x},
pages = {383--390},
title = {{Opening the Black Box - Data Driven Visualization of Neural Networks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1532820},
year = {2005}
}
@article{VanderMaaten2013,
abstract = {The paper presents an O(N log N)-implementation of t-SNE -- an embedding technique that is commonly used for the visualization of high-dimensional data in scatter plots and that normally runs in O(N\^{}2). The new implementation uses vantage-point trees to compute sparse pairwise similarities between the input data objects, and it uses a variant of the Barnes-Hut algorithm - an algorithm used by astronomers to perform N-body simulations - to approximate the forces between the corresponding points in the embedding. Our experiments show that the new algorithm, called Barnes-Hut-SNE, leads to substantial computational advantages over standard t-SNE, and that it makes it possible to learn embeddings of data sets with millions of objects.},
archivePrefix = {arXiv},
arxivId = {1301.3342},
author = {van der Maaten, Laurens},
eprint = {1301.3342},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/3. August/Report/extra literatures/1301.3342v2.pdf:pdf},
pages = {1--11},
title = {{Barnes-Hut-SNE}},
url = {http://arxiv.org/abs/1301.3342},
year = {2013}
}
@article{VanderMaaten2009,
abstract = {In recent years, a variety of nonlinear dimensionality reduction techniques have been proposed that aim to address the limitations of traditional techniques such as PCA and classical scaling. The paper presents a review and systematic comparison of these techniques. The performances of the nonlinear techniques are investigated on artificial and natural tasks. The results of the experiments reveal that nonlinear tech- niques perform well on selected artificial tasks, but that this strong performance does not necessarily extend to real-world tasks. The paper explains these results by identi- fying weaknesses of current nonlinear techniques, and suggests how the performance of nonlinear dimensionality reduction techniques may be improved.},
author = {van der Maaten, Laurens and Postma, Eric and van den Herik, Jaap},
doi = {10.1080/13506280444000102},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/dimensionality\_reduction\_a\_comparative\_review.pdf:pdf},
issn = {0169328X},
journal = {Journal of Machine Learning Research},
keywords = {dimensionality reduction,feature extraction,manifold learning},
number = {January},
pages = {1--41},
pmid = {7877450},
title = {{Dimensionality Reduction: A Comparative Review}},
volume = {10},
year = {2009}
}
@article{Victor2011,
author = {Victor, Bret},
title = {{Up and down the ladder of abstraction: a systematic approach to interactive visualization}},
url = {http://worrydream.com/\#!2/LadderOfAbstraction},
year = {2011}
}
@article{Victor2006,
abstract = {The ubiquity of frustrating, unhelpful software interfaces has motivated decades of research into Human-Computer Interaction. In this paper, I suggest that the long-standing focus on interaction may be misguided. For a majority subset of software, called information software, I argue that interactivity is actually a curse for users and a crutch for designers, and users' goals can be better satisfied through other means. Information software design can be seen as the design of context-sensitive information graphics. I demonstrate the crucial role of information graphic design, and present three approaches to context-sensitivity, of which interactivity is the last resort. After discussing the cultural changes necessary for these design ideas to take root, I address their implementation. I outline a tool which may allow designers to create data-dependent graphics with no engineering assistance, and also outline a platform which may allow an unprecedented level of implicit context-sharing between independent programs. I conclude by asserting that the principles of information software design will become critical as technology improves. Although this paper presents a number of concrete design and engineering ideas, the larger intent is to introduce a unified theory of information software design, and provide inspiration and direction for progressive designers who suspect that the world of software isn' t as flat as they' ve been told.},
author = {Victor, Bret},
doi = {10.1007/s00170-009-2118-4},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Victor - 2006 - Magic Ink.pdf:pdf},
journal = {Engineering},
pages = {509--515},
title = {{Magic Ink}},
url = {http://worrydream.com/MagicInk/},
year = {2006}
}
@article{Viegas2004,
abstract = {Visualizations have played an important role in generating new insights in social network analysis. We suggest that such visualizations can be of interest not only to analysts and researchers but also to the people whose data is being analyzed. In this paper we briefly talk about two visualizations of email that we developed to give people a better sense of their email archives and social networks. One visualization shows a traditional network graph with email contacts as nodes. The second visualization depicts the temporal rhythms of interactions in dyadic relationships between ego and individual contacts. While observing and interviewing users of these systems, it became clear that, when used in tandem, these visualizations complemented and clarified each others depiction of a persons social network. Based on our experience with these two systems, we propose that visualizations of social networks that are aimed at end users ought to go beyond the graph paradigm. We posit that basic cartographic principles such as adaptive zooming and multiple viewing modes provide system designers with useful visual solutions to the depiction of social networks.},
author = {Vi\'{e}gas, Fernanda B and Donath, Judith},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/viegas-cscw04.pdf:pdf},
journal = {Workshop on Social Networks CSCW},
pages = {6--10},
title = {{Social network visualization: Can we go beyond the graph}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.135.4963\&amp;rep=rep1\&amp;type=pdf},
volume = {4},
year = {2004}
}
@article{Vondrick2013,
archivePrefix = {arXiv},
arxivId = {arXiv:1502.05461v1},
author = {Vondrick, Carl Carl Martin},
eprint = {arXiv:1502.05461v1},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/mthesis.pdf:pdf},
title = {{Visualizing object detection features}},
year = {2013}
}
@article{Vondrick2013a,
abstract = {We introduce algorithms to visualize feature spaces used by object detectors. The tools in this paper allow a human to put on ‘HOG goggles’ and perceive the visual world as a HOG based object detector sees it. We found that these visualizations allow us to analyze object detection systems in new ways and gain new insight into the detector’s fail- ures. For example, when we visualize the features for high scoring false alarms, we discovered that, although they are clearly wrong in image space, they do look deceptively sim- ilar to true positives in feature space. This result suggests that many of these false alarms are caused by our choice of feature space, and indicates that creating a better learning algorithm or building bigger datasets is unlikely to correct these errors. By visualizing feature spaces, we can gain a more intuitive understanding of our detection systems.},
archivePrefix = {arXiv},
arxivId = {arXiv:1502.05461v1},
author = {Vondrick, Carl and Khosla, Aditya and Malisiewicz, Tomasz and Torralba, Antonio},
doi = {10.1109/ICCV.2013.8},
eprint = {arXiv:1502.05461v1},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/iccv.pdf:pdf},
isbn = {9781479928392},
issn = {1550-5499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
keywords = {hog,hoggles,object detection,visualization},
pages = {1--8},
title = {{HOGgles: Visualizing object detection features}},
year = {2013}
}
@article{Wang2015,
author = {Wang, Rui and Perez-Riverol, Yasset and Hermjakob, Henning and Vizca\'{\i}no, Juan Antonio},
doi = {10.1002/pmic.201400377},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/Wang\_et\_al-2015-PROTEOMICS.pdf:pdf},
issn = {16159853},
journal = {Proteomics},
keywords = {additional supporting information may,article at,be found in the,bioinformatics,chart,hierarchy,network,online version of this,s web-site,software library,the publisher},
number = {8},
pages = {1356--1374},
title = {{Open source libraries and frameworks for biological data visualisation: A guide for developers}},
url = {http://doi.wiley.com/10.1002/pmic.201400377},
volume = {15},
year = {2015}
}
@article{Wang2014,
author = {Wang, Zehan},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Wang - 2014 - Department of Computing Patch-based Segmentation with Spatial Context for Medical Image Analysis.pdf:pdf},
number = {September},
title = {{Department of Computing Patch-based Segmentation with Spatial Context for Medical Image Analysis}},
year = {2014}
}
@book{Ware2012,
abstract = {Most designers know that yellow text presented against a blue background reads clearly and easily, but how many can explain why, and what really are the best ways to help others and ourselves clearly see key patterns in a bunch of data? This book explores the art and science of why we see objects the way we do. Based on the science of perception and vision, the author presents the key principles at work for a wide range of applications--resulting in visualization of improved clarity, utility, and persuasiveness. The book offers practical guidelines that can be applied by anyone: interaction designers, graphic designers of all kinds (including web designers), data miners, and financial analysts.},
author = {Ware, Colin},
booktitle = {Information Visualization: Perception for Design},
doi = {10.1016/B978-0-12-381464-7.00001-6},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/book\_information-visualization-perception-for-design\_Ware\_Chapter1 (1).pdf:pdf},
isbn = {1558608192},
issn = {1473-8716},
pages = {1--27},
title = {{Foundation for a Science of Data Visualization}},
year = {2012}
}
@book{Ware2010,
abstract = {Summary: Increasingly, designers need to present information in ways that aid their audience's thinking process. Fortunately, results from the relatively new science of human visual perception provide valuable guidance. In Visual Thinking for Design, Colin Ware takes what we now know about perception, cognition, and attention and transforms it into concrete advice that designers can directly apply. He demonstrates how designs can be considered as tools for cognition - extensions of the viewer's brain in much the same way that a hammer is an extension of the user's hand. Experienced professional designe},
address = {Burlington},
annote = {Description based upon print version of record.},
author = {Ware, Colin.},
isbn = {ISBN: 9780080558417},
keywords = {Art.,Visual perception.,Visualization.},
publisher = {Elsevier Science},
title = {{Visual Thinking for Design : for Design}},
url = {http://ncl.eblib.com/patron/FullRecord.aspx?p=405649},
year = {2010}
}
@article{Ware2002,
author = {Ware, Malcolm and Frank, Eibe and Holmes, Geoffrey and Hall, Mark and Witten, Ian H.},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/Ware\_et\_al\_IJHCS.pdf:pdf},
journal = {Int. J. Hum.-Comput. Stud.},
title = {{Interactive Machine Learning : Letting Users Build Classifiers}},
year = {2002}
}
@article{Watcharapichat2012,
abstract = {Confocal laser endomicroscopy has recently emerged as a novel technology that brings major improvement to endoluminal imaging especially endoscopy for gastrointestinal tract. On the other hand, it could be a challenge for endoscopists as they need another specialized discipline, which is histology, and should be able to integrate this new domain knowledge into their clinical practice to make better medical judgement. This challenge is the motivation for us to initialize a computer-aided decision making system that has the ability to quantitatively analyze confocal images and return informative output which can assist endoscopists to improve their medical diagnosis. Primary objective of this project is to create a computer-aided decision support system that has the ability to assist endoscopists in establishing the final diagnosis on the information of confocal laser endomicroscopic images of the colon. We are particularly interested in confocal images of the colon because colon-related diseases are relatively common regardless ethnic. We develop a system based on ”content-based image retrieval” or CBIR method which has the ability to perform image search and finally present endoscopists a number of similar images from which they are able to decide themselves on the final diagnosis. The search according to CBIR analyzes image similarity based on image signatures derived from texture analysis using Gabor filters bank and texture distance between images is computed under Earth Mover’s distance with scale- and rotation-invariant features. We employ a ”patch technique” which is to select only certain parts of example images and search according to them instead of the conventional method which usually processes the entire example image. Moreover, we incorporate ”relevance feedback” which has potential to adapt the search behavior towards the user’s need. The mechanism of relevance feedback fundamentally operates on embedded manifold obtained from ”Isomap”. We conducted experiments on a database of 1000 confocal images which are all classified by clinical experts based on Miami classification. The final results showed that the patch technique outperformed the conventional method. Our system achieved the retrieval rate of 87.78\% when the ability to distinguish between neoplastic and benign categories is the criteria of accuracy. Interestingly, it achieved the retrieval rate of 58.89\% when the ability to return images with correct classification is the criteria to determine the accuracy of the system. In addition, there is also an ongoing preliminary experiment to study the feasibility to integrate an Eye Tracking system into our computer-aided decision support system and the result will be reported in the near future.},
author = {Watcharapichat, Pijika},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Watcharapichat - 2012 - Image processing and classification algorithm to detect cancerous cells morphology when using in-vivo probe-base.pdf:pdf},
number = {September},
pages = {1--65},
title = {{Image processing and classification algorithm to detect cancerous cells morphology when using in-vivo probe-based confocal laser endomicroscopy for the lower gastrointestinal tract}},
year = {2012}
}
@article{Watters2014,
abstract = {Neurons send signals to each other by means of sequences of action potentials (spikes). Ignoring variations in spike amplitude and shape that are probably not meaningful to a receiving cell, the information content, or entropy of the signal depends on only the timing of action potentials, and because there is no external clock, only the interspike intervals, and not the absolute spike times, are significant. Estimating spike train entropy is a difficult task, particularly with small data sets, and many methods of entropy estimation have been proposed. Here we present two related model-based methods for estimating the entropy of neural signals and compare them to existing methods. One of the methods is fast and reasonably accurate, and it converges well with short spike time records; the other is impractically time-consuming but apparently very accurate, relying on generating artificial data that are a statistical match to the experimental data. Using the slow, accurate method to generate a best-estimate entropy value, we find that the faster estimator converges to this value more closely and with smaller data sets than many existing entropy estimators.},
archivePrefix = {arXiv},
arxivId = {1309.2848v1},
author = {Watters, Nicholas and Reeke, George N},
doi = {10.1162/NECO},
eprint = {1309.2848v1},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/Thesis - DNN Visualisations -Academic Papers-.pdf:pdf},
issn = {1530888X},
journal = {Neural computation},
pages = {1840--1872},
pmid = {25602775},
title = {{Neuronal Spike Train Entropy Estimation by History Clustering}},
volume = {1872},
year = {2014}
}
@article{Weinberger2004,
author = {Weinberger, Kilian Q and Saul, Lawrence K},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/sde.pdf:pdf},
keywords = {kernels,machine learning},
number = {July},
title = {{Learning a kernel matrix for nonlinear dimensionality reduction}},
year = {2004}
}
@article{Wejchert1990,
author = {Wejchert, Jakub and Tesauro, Gerald},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/286-neural-network-visualization.pdf:pdf},
journal = {Advances in Neural Information Processing Systems 2},
pages = {465--472},
title = {{Neural Network Visualization}},
url = {http://papers.nips.cc/paper/286-neural-network-visualization.pdf$\backslash$nfiles/4502/Wejchert ? Tesauro - 1990 - Neural Network Visualization.pdf$\backslash$nfiles/4503/286-neural-network-visualization.html},
year = {1990}
}
@article{Whiteson2012,
abstract = {Algorithms for evolutionary computation, which simulate the process of natural selection to solve optimization problems, are an effective tool for discovering high-performing reinforcement-learning policies. Because they can automatically find good representations, handle continuous action spaces, and cope with partial observability, evolutionary reinforcement-learning approaches have a strong empirical track record, sometimes significantly outperforming temporal-difference methods. This chapter surveys research on the application of evolutionary computation to reinforcement learning, overviewing methods for evolving neural-network topologies and weights, hybrid methods that also use temporal-difference methods, coevolutionary methods for multi-agent settings, generative and developmental systems, and methods for on-line evolutionary reinforcement learning.},
author = {Whiteson, Shimon},
doi = {10.1007/978-3-642-27645-3\_10},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Whiteson - 2012 - Evolutionary Computation for Reinforcement Learning.pdf:pdf},
isbn = {364227644X},
issn = {1867-4534},
journal = {Reinforcement Learning: State of the Art},
number = {c},
pages = {1--30},
title = {{Evolutionary Computation for Reinforcement Learning}},
url = {http://staff.science.uva.nl/~whiteson/pubs/b2hd-whitesonrlsota11.html},
year = {2012}
}
@article{Wickham2010,
abstract = {A grammar of graphics is a tool that enables us to concisely describe the components of a graphic. Such a grammar allows us to move beyond named graphics (e.g., the "scatterplot") and gain insight into the deep structure that underlies statistical graphics. This article builds on Wilkinson, Anand, and Grossman (2005), describing extensions and refinements developed while building an open source implementation of the grammar of graphics for R, ggplot 2. The topics in this article include an introduction to the grammar by working through the process of creating a plot, and discussing the components that we need. The grammar is then presented formally and compared to Wilkinson's grammar, highlighting the hierarchy of defaults, and the implications of embedding a graphical grammar into a programming language. The power of the grammar is illustrated with a selection of examples that explore different components and their interactions, in more detail. The article concludes by discussing some perceptual issues, and thinking about how we can build on the grammar M learn how to create graphical "poems." Supplemental materials are available online.},
author = {Wickham, Hadley},
doi = {10.1198/jcgs.2009.07098},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/layered-grammar.pdf:pdf},
isbn = {1061-8600},
issn = {1061-8600},
journal = {Journal of Computational and Graphical Statistics},
keywords = {Grammar of graphics, Statistical graphics,grammar of graphics,statistical graphics},
number = {1},
pages = {3--28},
title = {{A Layered Grammar of Graphics}},
volume = {19},
year = {2010}
}
@article{Wickham2008,
abstract = {This thesis describes three families of tools for exploring data and models. It is organised in roughly the same way that you perform a data analysis. First, you get the data in a form that you can work with; Section 1.1 introduces the reshape framework for restructuring data, described fully in Chapter 2. Second, you plot the data to get a feel for what is going on; Section 1.2 introduces the layered grammar of graphics, described in Chapter 3. Third, you iterate between graphics and models to build a succinct quantitative summary of the data; Section 1.3 introduces strategies for visualising models, discussed in Chapter 4. Finally, you look back at what you have done, and contemplate what tools you need to do better in the future; Chapter 5 summarises the impact of my work and my plans for the future. The tools developed in this thesis are firmly based in the philosophy of exploratory data analysis (Tukey, 1977). With every view of the data, we strive to be both curious and sceptical. We keep an open mind towards alternative explanations, never believing we have found the best model. Due to space limitations, the following papers only give a glimpse at this philosophy of data analysis, but it underlies all of the tools and strategies that are developed. A fuller data analysis, using many of the tools developed in this thesis, is available in Hobbs et al. (To appear).},
author = {Wickham, Hadley Alexander},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/practical-tools-hadley-wickham.pdf:pdf},
issn = {0549543147},
pages = {105},
title = {{Practical tools for exploring data and models}},
year = {2008}
}
@article{Xie2013,
author = {Xie, Chun},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Xie - 2013 - Information Visualisation RIAs.pdf:pdf},
journal = {Evolution},
title = {{Information Visualisation RIAs}},
year = {2013}
}
@article{Yoshimi2008,
author = {Yoshimi, Jeff},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/10.1.1.176.7352.pdf:pdf},
keywords = {dimensionality reduction,neural,neural networks,simulation,virtual reality,visualization},
number = {May},
pages = {1--26},
title = {{Simbrain : A visual framework for neural network analysis and education}},
volume = {3},
year = {2008}
}
@article{Zeiler2013,
abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we address both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. We also perform an ablation study to discover the performance contribution from different model layers. This enables us to find model architectures that outperform Krizhevsky $\backslash$etal on the ImageNet classification benchmark. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
archivePrefix = {arXiv},
arxivId = {1311.2901},
author = {Zeiler, Matthew D and Fergus, Rob},
doi = {10.1007/978-3-319-10590-1\_53},
eprint = {1311.2901},
file = {:Users/ssfg/Library/Application Support/Mendeley Desktop/Downloaded/Zeiler, Fergus - 2013 - Visualizing and Understanding Convolutional Networks.pdf:pdf},
isbn = {978-3-319-10589-5},
journal = {arXiv preprint arXiv:1311.2901},
title = {{Visualizing and Understanding Convolutional Networks}},
url = {http://arxiv.org/abs/1311.2901},
year = {2013}
}
@article{Zeiler2011,
abstract = {We present a hierarchical model that learns image decompositions via alternating layers of convolutional sparse coding and max pooling. When trained on natural images, the layers of our model capture image information in a variety of forms: low-level edges, mid-level edge junctions, high-level object parts and complete objects. To build our model we rely on a novel inference scheme that ensures each layer reconstructs the input, rather than just the output of the layer directly beneath, as is common with existing hierarchical approaches. This makes it possible to learn multiple layers of representation and we show models with 4 layers, trained on images from the Caltech-101 and 256 datasets. When combined with a standard classifier, features extracted from these models outperform SIFT, as well as representations from other feature learning methods.},
author = {Zeiler, Matthew D. and Taylor, Graham W. and Fergus, Rob},
doi = {10.1109/ICCV.2011.6126474},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/0. Deep Learning/iccv2011.pdf:pdf},
isbn = {9781457711015},
issn = {1550-5499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {2018--2025},
title = {{Adaptive deconvolutional networks for mid and high level feature learning}},
year = {2011}
}
@misc{,
keywords = {0596102356,Building Scalable Web Sites: Building,COM051260,COM051320,Cal Henderson,Computer - Internet,Computer Books: Web Programming,Computers,Computers / Internet / General,Computers / Programming Languages / JavaScript,Computers / Programming Languages / XML,Computers / Software Development \& Engineering / G,Computers / User Interfaces,Computers / Web / Design,Computers / Web / General,Computers / Web / Page Design,Computing: Professional \& Programming,Design,Internet,O'Reilly Media,Scaling,Web - Design,Web graphics \& design,Web site development,Web sites,Web sites - Design,and Optimizing the Next Generation of Web Applicat},
title = {{Building Scalable Web Sites: Building, Scaling, and Optimizing the Next Generation of Web Applications: Cal Henderson: 9780596102357: Amazon.com: Books}},
url = {http://www.amazon.com/Building-Scalable-Web-Sites-applications/dp/0596102356/ref=sr\_1\_38?ie=UTF8\&s=books\&qid=1225742541\&sr=1-38},
urldate = {2015-05-23}
}
@article{,
doi = {10.1006/S1045-926X(02)00028-9},
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/1-s2.0-S1045926X02902375-main.pdf:pdf},
keywords = {algorithm visualization,e,ectiveness,empirical studies of,literature reviews,meta-analysis,software visualization},
title = {{A Meta-Study of AlgorithmVisualization E ¡ ectiveness}},
year = {2002}
}
@misc{,
keywords = {Kenny Bastani},
mendeley-tags = {Kenny Bastani},
title = {{Using 3D Visualization to Debug a Graph-based Algorithm}},
url = {http://www.kennybastani.com/2014/07/using-3d-visualization-to-debug-graph.html},
urldate = {2015-05-24}
}
@misc{,
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Visualisation/S1045926X02902375.html:html},
title = {{S1045926X02902375}}
}
@misc{,
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/Graphic Excellence.pdf:pdf},
title = {{Graphic Excellence.pdf}}
}
@misc{,
annote = {http://www.zingdesign.com/top-10-web-development-trends-and-predictions-for-2015/\#node-js},
keywords = {2015,New Zealand,Web design,Wellington,Zing Design,company,development,prediction,trends,web,web development},
title = {{Top 10 web development trends and predictions for 2015 | Zing Design}},
url = {http://www.zingdesign.com/top-10-web-development-trends-and-predictions-for-2015/\#node-js},
urldate = {2015-05-23}
}
@misc{,
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/1. June/1. Visualisation/Cleveland\_GraphicalPerception\_Science85.pdf:pdf},
title = {{Cleveland\_GraphicalPerception\_Science85.pdf}}
}
@article{,
file = {:Users/ssfg/Documents/2. University/3. INDIVIDUAL PROJECT/0. May 2015/Deep Neural Networks/ffnets-note.pdf:pdf},
title = {{2 Feed-forward Neural Networks Single Layer Perceptron}},
year = {1985}
}
@misc{,
title = {{Stanford University CS231n: Convolutional Neural Networks for Visual Recognition}},
url = {http://cs231n.stanford.edu/index.html},
urldate = {2015-06-12}
}
@article{Bernd1999,
author = {Bernd, T. and Kleutges, M. and Kroll, A.},
journal = {Neural Computing \& Applications},
title = {{Nonlinear Black Box Modelling – Fuzzy Networks versus Neural Networks}},
volume = {Volume 8, },
year = {1999}
}
@article{Nielsen,
author = {Nielsen, Michael},
title = {{Why are deep neural networks hard to train?}},
url = {http://neuralnetworksanddeeplearning.com/chap5.html}
}
@article{Blank2013,
author = {Blank, Steve},
journal = {Harvard Business Review},
title = {{Why the lean-startup changes everything}},
url = {https://hbr.org/2013/05/why-the-lean-start-up-changes-everything},
year = {2013}
}
